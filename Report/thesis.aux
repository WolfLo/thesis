\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{acronym}{alg}{acr}{acn}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesis.xdy}
\@glsorder{word}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@input{Abstract/abstract.aux}
\@input{Acknowledgements/acknowledgements.aux}
\citation{deisenroth2013survey}
\citation{brockman2016openai}
\citation{scott2015multivariate}
\citation{wawrzynski2005intensive}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{v}{chapter*.3}}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{vi}{chapter*.4}}
\@writefile{toc}{\contentsline {chapter}{List of Algorithms}{vii}{chapter*.5}}
\@writefile{toc}{\contentsline {chapter}{Acronyms}{viii}{section*.6}}
\citation{goodfellow2016deep}
\citation{sutton2018reinforcement}
\citation{thrun1992efficient}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{deisenroth2013survey}
\citation{sutton2000policy}
\citation{sehnke2008policy}
\citation{silver2014deterministic}
\citation{schulman2015trust}
\citation{mnih2016asynchronous}
\citation{espeholt2018impala}
\citation{ziebart2008maximum}
\citation{haarnoja2017reinforcement}
\citation{haarnoja2018soft}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation and Goal}{2}{section.1.1}}
\citation{auer2002finite}
\citation{lattimore2019bandit}
\citation{houthooft2016vime}
\citation{haarnoja2017reinforcement}
\citation{haarnoja2018soft}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Original Contributions}{3}{section.1.2}}
\citation{lai1985asymptotically}
\citation{agrawal1995sample}
\citation{auer2002using}
\citation{veach_optimally_1995}
\citation{bubeck2013bandits}
\citation{metelli2018policy}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Overview}{5}{section.1.3}}
\citation{lai1985asymptotically}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preliminaries}{6}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Preliminaries}{{2}{6}{Preliminaries}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Multi Armed Bandits}{6}{section.2.1}}
\newlabel{sec:mab}{{2.1}{6}{Multi Armed Bandits}{section.2.1}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {definition}{\numberline {2.1.1}Definition}{7}{definition.2.1.1}}
\@writefile{loe}{\contentsline {definition}{\numberline {2.1.2}Definition}{7}{definition.2.1.2}}
\newlabel{def:immediateregret}{{2.1.2}{7}{}{definition.2.1.2}{}}
\citation{lattimore2019bandit}
\@writefile{loe}{\contentsline {definition}{\numberline {2.1.3}Definition}{8}{definition.2.1.3}}
\newlabel{def:regret}{{2.1.3}{8}{}{definition.2.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Exploration and Exploitation}{8}{subsection.2.1.1}}
\newlabel{eedilemma}{{2.1.1}{8}{Exploration and Exploitation}{subsection.2.1.1}{}}
\citation{lattimore2019bandit}
\citation{lattimore2019bandit}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Stochastic Bandits With Finitely Many Arms}{9}{subsection.2.1.2}}
\newlabel{finiteMABs}{{2.1.2}{9}{Stochastic Bandits With Finitely Many Arms}{subsection.2.1.2}{}}
\newlabel{eq:averagereward}{{2.3}{9}{Stochastic Bandits With Finitely Many Arms}{equation.2.1.3}{}}
\newlabel{thmt@@regretETC@data}{{\def \theequation {2.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )2.1.\@arabic {\c@equation }}\setcounter {equation}{3}}{9}{Stochastic Bandits With Finitely Many Arms}{algorithm.2.1}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {2.1.1}Theorem}{9}{theorem.2.1.1}}
\newlabel{thmt@@regretETC}{{2.1.1}{9}{}{theorem.2.1.1}{}}
\newlabel{th:regretETC}{{2.1.1}{9}{}{theorem.2.1.1}{}}
\citation{agrawal1995continuum}
\citation{magureanu2014lipschitz}
\citation{bubeck2011x}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.1}{\ignorespaces Explore-then-commit\relax }}{10}{algorithm.2.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:explorethencommit}{{2.1}{10}{Explore-then-commit\relax }{algorithm.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}$\mathcal  {X}$-armed Bandits}{10}{subsection.2.1.3}}
\newlabel{sub:xarmedbandits}{{2.1.3}{10}{$\mathcal {X}$-armed Bandits}{subsection.2.1.3}{}}
\citation{puterman2014markov}
\citation{sutton2018reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Markov Decision Processes}{11}{section.2.2}}
\@writefile{loe}{\contentsline {definition}{\numberline {2.2.1}Definition}{11}{definition.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Interaction protocol for Markov decision processes\relax }}{12}{figure.caption.8}}
\newlabel{fig:MDP}{{2.1}{12}{Interaction protocol for Markov decision processes\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Policies}{13}{subsection.2.2.1}}
\@writefile{loe}{\contentsline {definition}{\numberline {2.2.2}Definition}{13}{definition.2.2.2}}
\@writefile{loe}{\contentsline {remark}{\numberline {2.2.1}Remark}{13}{remark.2.2.1}}
\citation{sutton2000policy}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Performance}{14}{subsection.2.2.2}}
\newlabel{eq:Jstartstate}{{2.6}{14}{Performance}{equation.2.2.6}{}}
\newlabel{eq:ssdistribution}{{2.7}{14}{Performance}{equation.2.2.7}{}}
\citation{baird1993advantage}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Value Functions}{15}{subsection.2.2.3}}
\newlabel{eq:BellmanV}{{2.11}{15}{Value Functions}{equation.2.2.11}{}}
\newlabel{eq:BellmanQ}{{2.13}{15}{Value Functions}{equation.2.2.13}{}}
\citation{sutton2018reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Reinforcement Learning}{16}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Problem Formulation}{16}{subsection.2.3.1}}
\citation{puterman2014markov}
\citation{sutton2018reinforcement}
\newlabel{eq:optimalpolicy}{{2.15}{17}{Problem Formulation}{equation.2.3.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Taxonomy}{17}{subsection.2.3.2}}
\citation{sutton1991dyna}
\citation{kupcsik2013data}
\citation{watkins1989learning}
\citation{rummery1994line}
\citation{williams1992simple}
\citation{watkins1989learning}
\citation{degris2012off}
\citation{rummery1994line}
\citation{sutton1988learning}
\citation{williams1992simple}
\citation{baxter2001infinite}
\citation{sutton2018reinforcement}
\citation{antos2008fitted}
\citation{grondman2012survey}
\citation{lange2012batch}
\citation{more1994line}
\citation{deisenroth2013survey}
\citation{sutton2000policy}
\citation{dayan1997using}
\citation{kober2009policy}
\citation{still2012information}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Policy Search}{20}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Overview}{20}{subsection.2.4.1}}
\newlabel{subsec:PSoverview}{{2.4.1}{20}{Overview}{subsection.2.4.1}{}}
\newlabel{eq:PSproblem}{{2.16}{20}{Overview}{equation.2.4.16}{}}
\citation{deisenroth2013survey}
\citation{deisenroth2013survey}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A taxonomy of \gls {PS} methods \cite  {deisenroth2013survey}\relax }}{21}{figure.caption.9}}
\newlabel{fig:PStaxonomy}{{2.2}{21}{A taxonomy of \gls {PS} methods \cite {deisenroth2013survey}\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Policy Gradient}{21}{subsection.2.4.2}}
\citation{sutton2000policy}
\newlabel{eq:paramsupdate}{{2.20}{22}{Policy Gradient}{equation.2.4.20}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {2.4.1}Theorem}{22}{theorem.2.4.1}}
\newlabel{th:PGtheorem}{{2.4.1}{22}{}{theorem.2.4.1}{}}
\newlabel{eq:PGtheorem}{{2.21}{22}{}{equation.2.4.21}{}}
\citation{williams1992simple}
\citation{sutton2000policy}
\newlabel{eq:reinforcetrick}{{2.21}{23}{Policy Gradient}{equation.2.4.21}{}}
\newlabel{eq:trajectoryPG}{{2.24}{23}{Policy Gradient}{equation.2.4.24}{}}
\citation{amari1998natural1}
\citation{amari1998natural1}
\citation{amari1998natural2}
\citation{peters2008reinforcement}
\citation{glynn1990likelihood}
\newlabel{eq:logpolicyestimate}{{2.26}{24}{Policy Gradient}{equation.2.4.26}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.2}{\ignorespaces Generic \gls {PG} algorithm\relax }}{25}{algorithm.2.2}}
\newlabel{alg:PG}{{2.2}{25}{Generic \gls {PG} algorithm\relax }{algorithm.2.2}{}}
\newlabel{step:PGestimation}{{5}{25}{Generic \gls {PG} algorithm\relax }{algorithm.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Policy Gradient Estimation}{25}{subsection.2.4.3}}
\citation{williams1992simple}
\citation{williams1992simple}
\citation{peters2008reinforcement}
\citation{zhao2011analysis}
\newlabel{eq:PGbaseline}{{2.29}{26}{Policy Gradient Estimation}{equation.2.4.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Algorithms}{26}{subsection.2.4.4}}
\newlabel{subsec:algorithms}{{2.4.4}{26}{Algorithms}{subsection.2.4.4}{}}
\newlabel{eq:REINFORCE}{{2.30}{26}{Algorithms}{equation.2.4.30}{}}
\citation{baxter2001infinite}
\citation{sutton2000policy}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.3}{\ignorespaces Episodic REINFORCE with component-wise optimal baseline.\relax }}{27}{algorithm.2.3}}
\newlabel{alg:REINFORCE}{{2.3}{27}{Episodic REINFORCE with component-wise optimal baseline.\relax }{algorithm.2.3}{}}
\citation{peters2008reinforcement}
\citation{zhao2011analysis}
\citation{sehnke2008policy}
\citation{sehnke2010parameter}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.4}{\ignorespaces Episodic \gls {PGPE}\relax }}{29}{algorithm.2.4}}
\newlabel{alg:PGPE}{{2.4}{29}{Episodic \gls {PGPE}\relax }{algorithm.2.4}{}}
\citation{cochran2007sampling}
\citation{mcbook}
\citation{mcbook}
\citation{veach_optimally_1995}
\citation{veach_optimally_1995}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Multiple Importance Sampling}{30}{section.2.5}}
\newlabel{sec:mis}{{2.5}{30}{Multiple Importance Sampling}{section.2.5}{}}
\newlabel{eq:ise}{{2.37}{30}{Multiple Importance Sampling}{equation.2.5.37}{}}
\newlabel{eq:mise}{{2.38}{30}{Multiple Importance Sampling}{equation.2.5.38}{}}
\citation{veach_optimally_1995}
\citation{renyi1961measures}
\citation{cortes2010learning}
\citation{metelli2018policy}
\newlabel{eq:bhw}{{2.39}{31}{Multiple Importance Sampling}{equation.2.5.39}{}}
\newlabel{eq:bhe}{{2.40}{31}{Multiple Importance Sampling}{equation.2.5.40}{}}
\newlabel{eq:renyi}{{2.41}{31}{Multiple Importance Sampling}{equation.2.5.41}{}}
\newlabel{thmt@@misevarbound@data}{{\def \theequation {2.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )2.5.\@arabic {\c@equation }}\setcounter {equation}{43}}{31}{Multiple Importance Sampling}{equation.2.5.43}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {2.5.1}Lemma}{31}{lemma.2.5.1}}
\newlabel{thmt@@misevarbound}{{2.5.1}{31}{}{lemma.2.5.1}{}}
\newlabel{lem:misevarbound}{{2.5.1}{31}{}{lemma.2.5.1}{}}
\citation{thrun1992efficient}
\citation{whitehead1991study}
\citation{thrun1992efficient}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Exploration Techniques}{33}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:sota}{{3}{33}{Exploration Techniques}{chapter.3}{}}
\citation{lattimore2019bandit}
\citation{auer2002finite}
\citation{cesa2017boltzmann}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Exploration in Multi Armed Bandits}{34}{section.3.1}}
\newlabel{sec:expinmab}{{3.1}{34}{Exploration in Multi Armed Bandits}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Undirected Exploration}{34}{subsection.3.1.1}}
\citation{lai1985asymptotically}
\citation{agrawal1995continuum}
\citation{auer2002finite}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Count-based Exploration and Upper Confidence Bound}{35}{subsection.3.1.2}}
\newlabel{sebsec:count&UCB}{{3.1.2}{35}{Count-based Exploration and Upper Confidence Bound}{subsection.3.1.2}{}}
\citation{lattimore2019bandit}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {definition}{\numberline {3.1.1}Definition}{36}{definition.3.1.1}}
\newlabel{def:subgaussianity}{{3.1.1}{36}{}{definition.3.1.1}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {3.1.1}Theorem}{36}{theorem.3.1.1}}
\@writefile{loe}{\contentsline {corollary}{\numberline {3.1.1}Corollary}{36}{corollary.3.1.1}}
\newlabel{cor:subgaussian}{{3.1.1}{36}{}{corollary.3.1.1}{}}
\newlabel{eq:ucb}{{3.4}{36}{Count-based Exploration and Upper Confidence Bound}{equation.3.1.4}{}}
\citation{auer2002finite}
\citation{agrawal1995continuum}
\citation{auer2002finite}
\citation{auer2010ucb}
\citation{garivier2011kl}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.1}{\ignorespaces \gls {UCB}($\delta $) algorithm\relax }}{37}{algorithm.3.1}}
\newlabel{alg:ucb}{{3.1}{37}{\gls {UCB}($\delta $) algorithm\relax }{algorithm.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Optimism in the Face of Uncertainty}{37}{subsection.3.1.3}}
\citation{bubeck2011x}
\citation{kleinberg2005nearly}
\citation{kleinberg2008multi}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4} Hierarchical Optimistic Optimization}{38}{subsection.3.1.4}}
\newlabel{sub:hoo}{{3.1.4}{38}{Hierarchical Optimistic Optimization}{subsection.3.1.4}{}}
\@writefile{loe}{\contentsline {definition}{\numberline {3.1.2}Definition}{39}{definition.3.1.2}}
\newlabel{def:treeofcoverings}{{3.1.2}{39}{}{definition.3.1.2}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {3.1.1}Remark}{39}{remark.3.1.1}}
\citation{bubeck2011x}
\@writefile{loe}{\contentsline {assumption}{\numberline {3.1.1}Assumption}{40}{assumption.3.1.1}}
\newlabel{eq:weaklipschitz}{{3.12}{40}{}{equation.3.1.12}{}}
\citation{thompson1933likelihood}
\citation{russo2013eluder}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.2}{\ignorespaces \gls {HOO} algorithm\relax }}{41}{algorithm.3.2}}
\newlabel{alg:hoo}{{3.2}{41}{\gls {HOO} algorithm\relax }{algorithm.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Posterior Sampling}{41}{subsection.3.1.5}}
\newlabel{sub:posteriorMAB}{{3.1.5}{41}{Posterior Sampling}{subsection.3.1.5}{}}
\citation{agrawal2013further}
\citation{bubeck2012regret}
\citation{russo2018tutorial}
\citation{srinivas2010gaussian}
\citation{srinivas2010gaussian}
\citation{williams2006gaussian}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.3}{\ignorespaces \gls {TS} for Bernoulli MAB with Beta priors\relax }}{43}{algorithm.3.3}}
\newlabel{alg:bernoulliTS}{{3.3}{43}{\gls {TS} for Bernoulli MAB with Beta priors\relax }{algorithm.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Gaussian Process Upper Confidence Bound}{43}{subsection.3.1.6}}
\citation{sutton2018reinforcement}
\citation{thrun1992efficient}
\citation{cesa2017boltzmann}
\citation{sallans2004reinforcement}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.4}{\ignorespaces \gls {GPUCB}\relax }}{45}{algorithm.3.4}}
\newlabel{alg:gpucb}{{3.4}{45}{\gls {GPUCB}\relax }{algorithm.3.4}{}}
\newlabel{eq:gpucbrule}{{3}{45}{\gls {GPUCB}\relax }{algorithm.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Exploration in Reinforcement Learning}{45}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Undirected Exploration}{45}{subsection.3.2.1}}
\citation{ziebart2008maximum}
\citation{haarnoja2017reinforcement}
\citation{haarnoja2018soft}
\citation{haarnoja2017reinforcement}
\citation{haarnoja2017reinforcement}
\citation{haarnoja2018soft}
\citation{kearns2002near}
\citation{brafman2002r}
\citation{auer2007logarithmic}
\citation{bellemare2016unifying}
\citation{tang2017exploration}
\citation{ostrovski2017count}
\citation{choshen2018dora}
\citation{bellemare2016unifying}
\citation{ostrovski2017count}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Count-based Exploration and Intrinsic Motivation}{47}{subsection.3.2.2}}
\citation{ostrovski2017count}
\citation{oord2016pixel}
\citation{lopes2012exploration}
\citation{oudeyer2007intrinsic}
\citation{chentanez2005intrinsically}
\citation{schmidhuber1991possibility}
\citation{bellemare2016unifying}
\citation{houthooft2016vime}
\citation{blei2017variational}
\newlabel{eq:augmentedreward}{{3.29}{50}{Count-based Exploration and Intrinsic Motivation}{equation.3.2.29}{}}
\newlabel{eq:elb}{{3.30}{50}{Count-based Exploration and Intrinsic Motivation}{equation.3.2.30}{}}
\citation{blundell2015weight}
\citation{houthooft2016vime}
\citation{strens2000bayesian}
\citation{osband2013more}
\citation{osband2015bootstrapped}
\citation{osband2016deep}
\citation{strens2000bayesian}
\citation{osband2017posterior}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.5}{\ignorespaces \gls {VIME}\relax }}{51}{algorithm.3.5}}
\newlabel{alg:VIME}{{3.5}{51}{\gls {VIME}\relax }{algorithm.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Posterior Sampling}{51}{subsection.3.2.3}}
\newlabel{sub:posteriorRL}{{3.2.3}{51}{Posterior Sampling}{subsection.3.2.3}{}}
\citation{metelli2018policy}
\citation{ionides2008truncated}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Optimistic Policy Search via Multiple Importance Sampling}{53}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:core}{{4}{53}{Optimistic Policy Search via Multiple Importance Sampling}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Robust Importance Sampling Estimation}{53}{section.4.1}}
\newlabel{sec:robust}{{4.1}{53}{Robust Importance Sampling Estimation}{section.4.1}{}}
\newlabel{eq:truncatedise}{{4.1}{54}{Robust Importance Sampling Estimation}{equation.4.1.1}{}}
\newlabel{eq:truncatedmise}{{4.2}{54}{Robust Importance Sampling Estimation}{equation.4.1.2}{}}
\newlabel{thmt@@truncatedbias@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.1.\@arabic {\c@equation }}\setcounter {equation}{2}}{54}{Robust Importance Sampling Estimation}{equation.4.1.2}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {lemma}{\numberline {4.1.1}Lemma}{54}{lemma.4.1.1}}
\newlabel{thmt@@truncatedbias}{{4.1.1}{54}{}{lemma.4.1.1}{}}
\newlabel{lem:truncatedbias}{{4.1.1}{54}{}{lemma.4.1.1}{}}
\newlabel{eq:biastruncated}{{4.3}{54}{}{equation.4.1.3}{}}
\newlabel{eq:variancetruncated}{{4.4}{54}{}{equation.4.1.4}{}}
\citation{bubeck2013bandits}
\citation{bubeck2013bandits}
\citation{ionides2008truncated}
\newlabel{thmt@@thrucatedconcentration@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.1.\@arabic {\c@equation }}\setcounter {equation}{4}}{55}{Robust Importance Sampling Estimation}{equation.4.1.4}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.1.1}Theorem}{55}{theorem.4.1.1}}
\newlabel{thmt@@thrucatedconcentration}{{4.1.1}{55}{}{theorem.4.1.1}{}}
\newlabel{lem:thrucatedconcentration}{{4.1.1}{55}{}{theorem.4.1.1}{}}
\newlabel{eq:1.1}{{4.5}{55}{}{equation.4.1.5}{}}
\newlabel{eq:1.2}{{4.6}{55}{}{equation.4.1.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Problem Formalization}{55}{section.4.2}}
\newlabel{sec:problem}{{4.2}{55}{Problem Formalization}{section.4.2}{}}
\citation{kleinberg2013bandits}
\newlabel{eq:theproblem}{{4.7}{56}{Problem Formalization}{equation.4.2.7}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {4.2.1}Remark}{56}{remark.4.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Algorithms}{57}{section.4.3}}
\newlabel{sec:algo}{{4.3}{57}{Algorithms}{section.4.3}{}}
\newlabel{eq:wcmu}{{4.8}{57}{Algorithms}{equation.4.3.8}{}}
\newlabel{eq:optimistindex}{{4.9}{57}{Algorithms}{equation.4.3.9}{}}
\citation{srinivas2010gaussian}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.1}{\ignorespaces \gls {OPTIMIST}\relax }}{58}{algorithm.4.1}}
\newlabel{alg:1}{{4.1}{58}{\gls {OPTIMIST}\relax }{algorithm.4.1}{}}
\newlabel{line:sampling}{{2}{58}{\gls {OPTIMIST}\relax }{algorithm.4.1}{}}
\newlabel{line:optstep}{{4}{58}{\gls {OPTIMIST}\relax }{algorithm.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Regret Analysis}{58}{section.4.4}}
\newlabel{sec:regret}{{4.4}{58}{Regret Analysis}{section.4.4}{}}
\newlabel{eq:inregret}{{4.10}{58}{Regret Analysis}{equation.4.4.10}{}}
\citation{srinivas2010gaussian}
\citation{bubeck2013bandits}
\newlabel{eq:regret}{{4.11}{59}{Regret Analysis}{equation.4.4.11}{}}
\newlabel{thmt@@boundrenyi@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{59}{Regret Analysis}{equation.4.4.11}{}}
\@writefile{loe}{\contentsline {assumption}{\numberline {4.4.1}Assumption}{59}{assumption.4.4.1}}
\newlabel{thmt@@boundrenyi}{{4.4.1}{59}{}{assumption.4.4.1}{}}
\newlabel{ass:boundrenyi}{{4.4.1}{59}{}{assumption.4.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Discrete arm set}{59}{subsection.4.4.1}}
\newlabel{thmt@@regretdiscrete@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{59}{Discrete arm set}{subsection.4.4.1}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.1}Theorem}{59}{theorem.4.4.1}}
\newlabel{thmt@@regretdiscrete}{{4.4.1}{59}{}{theorem.4.4.1}{}}
\newlabel{th:regretdiscrete}{{4.4.1}{59}{}{theorem.4.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Compact arm set}{60}{subsection.4.4.2}}
\newlabel{thmt@@lipschitz@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{60}{Compact arm set}{subsection.4.4.2}{}}
\@writefile{loe}{\contentsline {assumption}{\numberline {4.4.2}Assumption}{60}{assumption.4.4.2}}
\newlabel{thmt@@lipschitz}{{4.4.2}{60}{}{assumption.4.4.2}{}}
\newlabel{ass:lipschitz}{{4.4.2}{60}{}{assumption.4.4.2}{}}
\newlabel{thmt@@lipschitzpol@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{60}{Compact arm set}{assumption.4.4.2}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {4.4.1}Lemma}{60}{lemma.4.4.1}}
\newlabel{thmt@@lipschitzpol}{{4.4.1}{60}{}{lemma.4.4.1}{}}
\newlabel{lem:lispschitzpol}{{4.4.1}{60}{}{lemma.4.4.1}{}}
\newlabel{eq:lp1}{{4.12}{60}{}{equation.4.4.12}{}}
\newlabel{eq:lp2}{{4.13}{60}{}{equation.4.4.13}{}}
\newlabel{thmt@@regretcompact@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{13}}{60}{Compact arm set}{equation.4.4.13}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.2}Theorem}{60}{theorem.4.4.2}}
\newlabel{thmt@@regretcompact}{{4.4.2}{60}{}{theorem.4.4.2}{}}
\newlabel{th:regretcompact}{{4.4.2}{60}{}{theorem.4.4.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.2}{\ignorespaces \gls {OPTIMIST}2\relax }}{61}{algorithm.4.2}}
\newlabel{alg:2}{{4.2}{61}{\gls {OPTIMIST}2\relax }{algorithm.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Discretization}{61}{subsection.4.4.3}}
\newlabel{thmt@@regretdiscretized@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{13}}{61}{Discretization}{subsection.4.4.3}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.3}Theorem}{61}{theorem.4.4.3}}
\newlabel{thmt@@regretdiscretized}{{4.4.3}{61}{}{theorem.4.4.3}{}}
\newlabel{th:regretdiscretized}{{4.4.3}{61}{}{theorem.4.4.3}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {4.4.1}Remark}{62}{remark.4.4.1}}
\citation{baselines}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Numerical Simulations}{63}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:experiments}{{5}{63}{Numerical Simulations}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Practical Aspects}{63}{section.5.1}}
\newlabel{sec:practical}{{5.1}{63}{Practical Aspects}{section.5.1}{}}
\citation{gil2013renyi}
\citation{gil2013renyi}
\citation{gil2013renyi}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Divergence Between Gaussian Multivariate Distributions}{64}{subsection.5.1.1}}
\newlabel{thmt@@armonic@data}{{\def \theequation {5.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )5.1.\@arabic {\c@equation }}\setcounter {equation}{2}}{64}{Divergence Between Gaussian Multivariate Distributions}{subsection.5.1.1}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {theorem}{\numberline {5.1.1}Theorem}{64}{theorem.5.1.1}}
\newlabel{thmt@@armonic}{{5.1.1}{64}{}{theorem.5.1.1}{}}
\newlabel{th:armonic}{{5.1.1}{64}{}{theorem.5.1.1}{}}
\newlabel{eq:gaussianrenyi}{{5.4}{64}{Divergence Between Gaussian Multivariate Distributions}{equation.5.1.4}{}}
\citation{peters2008reinforcement}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Uniformly Bounded R\IeC {\'e}nyi divergence}{65}{subsection.5.1.2}}
\newlabel{subsec:boundrenyi}{{5.1.2}{65}{Uniformly Bounded Rényi divergence}{subsection.5.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Linear Quadratic Gaussian Regulator}{65}{section.5.2}}
\citation{dorato1995linear}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Environmental coefficients (left-side), task coefficients (center) and \gls {OPTIMIST} input parameters (right-side) for the \gls {LQG} experiments.\relax }}{67}{table.caption.10}}
\newlabel{tab:LQGcoeff}{{5.1}{67}{Environmental coefficients (left-side), task coefficients (center) and \gls {OPTIMIST} input parameters (right-side) for the \gls {LQG} experiments.\relax }{table.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Cumulative regret in the \gls {LQG} experiment. Comparison between \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning the hyperpolicy mean. (30 runs, 95\% c.i.)\relax }}{67}{figure.caption.11}}
\newlabel{fig:LQGcomparison}{{5.1}{67}{Cumulative regret in the \gls {LQG} experiment. Comparison between \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning the hyperpolicy mean. (30 runs, 95\% c.i.)\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces The gain parameter $\mu $ selected at each iteration of \gls {GPUCB} (left) and \gls {OPTIMIST} (right) in the \gls {LQG} experiment.\relax }}{67}{figure.caption.12}}
\newlabel{fig:LQGmu}{{5.2}{67}{The gain parameter $\mu $ selected at each iteration of \gls {GPUCB} (left) and \gls {OPTIMIST} (right) in the \gls {LQG} experiment.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Mean return of arms $\mu \in [-0.9,-0,5]$, calculated by averaging the return collected over 2000 trajectories in the \gls {LQG} experiment.\relax }}{68}{figure.caption.13}}
\newlabel{fig:LQGoptimalgain}{{5.3}{68}{Mean return of arms $\mu \in [-0.9,-0,5]$, calculated by averaging the return collected over 2000 trajectories in the \gls {LQG} experiment.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Gain only}{68}{subsection.5.2.1}}
\citation{brockman2016openai}
\citation{brockman2016openai}
\citation{brockman2016openai}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Continuous Mountain Car experiment.\relax }}{69}{table.caption.16}}
\newlabel{tab:MCcoeff}{{5.2}{69}{Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Continuous Mountain Car experiment.\relax }{table.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Gain and standard deviation}{69}{subsection.5.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Cumulative regret in the \gls {LQG} experiment, comparing \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning both the mean and the standard deviation hyperparameters. (30 runs, 95\% c.i.)\relax }}{70}{figure.caption.14}}
\newlabel{fig:LQGcomparisonVar}{{5.4}{70}{Cumulative regret in the \gls {LQG} experiment, comparing \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning both the mean and the standard deviation hyperparameters. (30 runs, 95\% c.i.)\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Graphical representation of the Mountain Car problem \cite  {brockman2016openai}.\relax }}{70}{figure.caption.15}}
\newlabel{fig:MC}{{5.5}{70}{Graphical representation of the Mountain Car problem \cite {brockman2016openai}.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Continuous Mountain Car}{70}{section.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Cumulative regret in the Continuous Mountain Car experiment. Comparison between \gls {OPTIMIST}, \gls {PGPE} and \gls {PBPOIS} when learning the two-dimensional hyperpolicy mean. (5 runs, 95\% c.i.)\relax }}{71}{figure.caption.17}}
\newlabel{fig:MCcomparison}{{5.6}{71}{Cumulative regret in the Continuous Mountain Car experiment. Comparison between \gls {OPTIMIST}, \gls {PGPE} and \gls {PBPOIS} when learning the two-dimensional hyperpolicy mean. (5 runs, 95\% c.i.)\relax }{figure.caption.17}{}}
\citation{metelli2018policy}
\citation{scott2015multivariate}
\citation{scott2015multivariate}
\citation{scott2015multivariate}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Gaussian kernel density estimation \cite  {scott2015multivariate} of the probability distribution of the arm set $\bm  {\xi }=\bm  {\mu }$ induced by \gls {PGPE} (left) and \gls {OPTIMIST} (right).\relax }}{73}{figure.caption.18}}
\newlabel{fig:MCgain}{{5.7}{73}{Gaussian kernel density estimation \cite {scott2015multivariate} of the probability distribution of the arm set $\vxi =\vmu $ induced by \gls {PGPE} (left) and \gls {OPTIMIST} (right).\relax }{figure.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Number of points in the discretized state space, following discretization schedule $\tau _t=\delimiter "4D72E50 t^{\frac  {1}{\kappa }} \delimiter "5D73E54 $, where $d$ refers to the number of space dimensions and $k$ is a free-parameter.\relax }}{73}{table.caption.19}}
\newlabel{tab:granularity}{{5.3}{73}{Number of points in the discretized state space, following discretization schedule $\tau _t=\lceil t^{\frac {1}{\kappa }} \rceil $, where $d$ refers to the number of space dimensions and $k$ is a free-parameter.\relax }{table.caption.19}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {5.3.1}Remark}{73}{remark.5.3.1}}
\newlabel{rk:undiscounted}{{5.3.1}{73}{}{remark.5.3.1}{}}
\citation{wawrzynski2005intensive}
\citation{wawrzynski2005intensive}
\citation{tornio2006variational}
\citation{duan2016benchmarking}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Graphical representation of the Inverted Pendulum task \cite  {wawrzynski2005intensive}.\relax }}{74}{figure.caption.20}}
\newlabel{fig:invpend}{{5.8}{74}{Graphical representation of the Inverted Pendulum task \cite {wawrzynski2005intensive}.\relax }{figure.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Inverted Pendulum experiment.\relax }}{74}{table.caption.21}}
\newlabel{tab:IPcoeff}{{5.4}{74}{Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Inverted Pendulum experiment.\relax }{table.caption.21}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {5.3.2}Remark}{74}{remark.5.3.2}}
\newlabel{rk:discretization}{{5.3.2}{74}{}{remark.5.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Inverted Pendulum}{74}{section.5.4}}
\citation{kimura1999efficient}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Action-based setting}{76}{section.5.5}}
\newlabel{sec:actionbased}{{5.5}{76}{Action-based setting}{section.5.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces The hyperpolicy mean parameter selected at each iteration of \gls {OPTIMIST} in the Inverted Pendulum experiment.\relax }}{77}{figure.caption.22}}
\newlabel{fig:IPmu1}{{5.9}{77}{The hyperpolicy mean parameter selected at each iteration of \gls {OPTIMIST} in the Inverted Pendulum experiment.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Truncated \gls {MIS} estimator (left) and exploration bonus (right) of the arms selected by \gls {OPTIMIST} at each iteration of the Inverted Pendulum experiment.\relax }}{77}{figure.caption.23}}
\newlabel{fig:IPbound}{{5.10}{77}{Truncated \gls {MIS} estimator (left) and exploration bonus (right) of the arms selected by \gls {OPTIMIST} at each iteration of the Inverted Pendulum experiment.\relax }{figure.caption.23}{}}
\citation{martino2017effective}
\citation{kong1992note}
\citation{kong1992note}
\newlabel{eq:essrenyi}{{5.13}{78}{Action-based setting}{equation.5.5.13}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions}{79}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:conclusions}{{6}{79}{Conclusions}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Recapitulation}{79}{section.6.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Limitations and Future Works}{80}{section.6.2}}
\citation{metelli2018policy}
\@writefile{toc}{\contentsline {chapter}{Appendices}{82}{section*.24}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Proofs}{82}{Appendix.1.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:proof}{{A}{82}{Proofs}{Appendix.1.A}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {lemma}{\numberline {2.5.1}Lemma}{82}{lemma.dummy.41}}
\newlabel{p:misevarboundline2}{{A.1}{82}{Proofs}{equation.1.A.0.1}{}}
\newlabel{p:misevarboundline5}{{A.2}{82}{Proofs}{equation.1.A.0.2}{}}
\newlabel{eq:expectationdecomposition}{{A.3}{83}{Proofs}{equation.1.A.0.3}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {4.1.1}Lemma}{83}{lemma.dummy.43}}
\newlabel{p:truncatedbias1}{{A.5}{83}{Proofs}{equation.1.A.0.5}{}}
\newlabel{p:truncatedbias2}{{A.6}{84}{Proofs}{equation.1.A.0.6}{}}
\newlabel{p:truncatedbias3}{{A.7}{84}{Proofs}{equation.1.A.0.7}{}}
\newlabel{p:truncatedbias4}{{A.8}{84}{Proofs}{equation.1.A.0.8}{}}
\newlabel{p:truncatedbias5}{{A.9}{84}{Proofs}{equation.1.A.0.9}{}}
\citation{boucheron2013concentration}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.1.1}Theorem}{85}{theorem.dummy.45}}
\newlabel{p:thrucatedconcentration1}{{A.10}{85}{Proofs}{equation.1.A.0.10}{}}
\newlabel{p:thrucatedconcentration2}{{A.11}{85}{Proofs}{equation.1.A.0.11}{}}
\newlabel{p:thrucatedconcentration3}{{A.12}{85}{Proofs}{equation.1.A.0.12}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.1}Theorem}{86}{theorem.dummy.47}}
\newlabel{aux:1}{{A.14}{86}{Proofs}{equation.1.A.0.14}{}}
\newlabel{pp:1}{{A.15}{86}{Proofs}{equation.1.A.0.15}{}}
\newlabel{pp:2}{{A.16}{86}{Proofs}{equation.1.A.0.16}{}}
\newlabel{pp:3}{{A.17}{86}{Proofs}{equation.1.A.0.17}{}}
\newlabel{pp:4}{{A.18}{87}{Proofs}{equation.1.A.0.18}{}}
\newlabel{pp:5}{{A.19}{87}{Proofs}{equation.1.A.0.19}{}}
\newlabel{aux:2}{{A.20}{87}{Proofs}{equation.1.A.0.20}{}}
\newlabel{pp:6}{{A.21}{87}{Proofs}{equation.1.A.0.21}{}}
\newlabel{pp:7}{{A.22}{87}{Proofs}{equation.1.A.0.22}{}}
\newlabel{pp:8}{{A.23}{87}{Proofs}{equation.1.A.0.23}{}}
\newlabel{pp:9}{{A.24}{87}{Proofs}{equation.1.A.0.24}{}}
\citation{sutton2000policy}
\citation{sutton2000policy}
\newlabel{aux:3}{{A.25}{88}{Proofs}{equation.1.A.0.25}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {4.4.1}Lemma}{88}{lemma.dummy.49}}
\newlabel{aux:4}{{A.26}{88}{Proofs}{equation.1.A.0.26}{}}
\newlabel{pp:10}{{A.27}{88}{Proofs}{equation.1.A.0.27}{}}
\newlabel{pp:11}{{A.28}{88}{Proofs}{equation.1.A.0.28}{}}
\newlabel{eq:gauss}{{A.29}{88}{Proofs}{equation.1.A.0.29}{}}
\citation{srinivas2010gaussian}
\newlabel{pp:14}{{A.30}{89}{Proofs}{equation.1.A.0.30}{}}
\newlabel{aux:5}{{A.31}{89}{Proofs}{equation.1.A.0.31}{}}
\newlabel{pp:12}{{A.32}{89}{Proofs}{equation.1.A.0.32}{}}
\newlabel{pp:13}{{A.33}{89}{Proofs}{equation.1.A.0.33}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.2}Theorem}{89}{theorem.dummy.51}}
\newlabel{aux:6}{{A.34}{90}{Proofs}{equation.1.A.0.34}{}}
\newlabel{aux:7}{{A.35}{90}{Proofs}{equation.1.A.0.35}{}}
\newlabel{aux:8}{{A.36}{90}{Proofs}{equation.1.A.0.36}{}}
\newlabel{aux:9}{{A.37}{90}{Proofs}{equation.1.A.0.37}{}}
\newlabel{pp:15}{{A.38}{90}{Proofs}{equation.1.A.0.38}{}}
\newlabel{pp:16}{{A.39}{91}{Proofs}{equation.1.A.0.39}{}}
\newlabel{aux:10}{{A.40}{91}{Proofs}{equation.1.A.0.40}{}}
\newlabel{pp:17}{{A.41}{91}{Proofs}{equation.1.A.0.41}{}}
\newlabel{pp:18}{{A.42}{91}{Proofs}{equation.1.A.0.42}{}}
\newlabel{pp:19}{{A.43}{91}{Proofs}{equation.1.A.0.43}{}}
\newlabel{pp:20}{{A.45}{91}{Proofs}{equation.1.A.0.45}{}}
\newlabel{pp:21}{{A.47}{91}{Proofs}{equation.1.A.0.47}{}}
\newlabel{pp:22}{{A.51}{92}{Proofs}{equation.1.A.0.51}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.3}Theorem}{92}{theorem.dummy.53}}
\newlabel{aux:11}{{A.52}{92}{Proofs}{equation.1.A.0.52}{}}
\newlabel{pp:23}{{A.53}{92}{Proofs}{equation.1.A.0.53}{}}
\newlabel{pp:24}{{A.54}{93}{Proofs}{equation.1.A.0.54}{}}
\newlabel{aux:12}{{A.55}{93}{Proofs}{equation.1.A.0.55}{}}
\newlabel{pp:25}{{A.56}{93}{Proofs}{equation.1.A.0.56}{}}
\newlabel{pp:26}{{A.57}{93}{Proofs}{equation.1.A.0.57}{}}
\newlabel{pp:27}{{A.58}{93}{Proofs}{equation.1.A.0.58}{}}
\newlabel{pp:28}{{A.60}{93}{Proofs}{equation.1.A.0.60}{}}
\newlabel{pp:29}{{A.62}{93}{Proofs}{equation.1.A.0.62}{}}
\newlabel{pp:30}{{A.64}{93}{Proofs}{equation.1.A.0.64}{}}
\citation{hershey2007approximating}
\@writefile{loe}{\contentsline {lemma}{\numberline {A.0.1}Lemma}{94}{lemma.1.A.0.1}}
\newlabel{eq:strangeBound}{{A.68}{95}{Proofs}{equation.1.A.0.68}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {5.1.1}Theorem}{95}{theorem.dummy.56}}
\bibstyle{apalike}
\bibdata{Bibliography/bibliography}
\bibcite{agrawal1995continuum}{Agrawal, 1995a}
\bibcite{agrawal1995sample}{Agrawal, 1995b}
\bibcite{agrawal2013further}{Agrawal and Goyal, 2013}
\bibcite{amari1998natural2}{Amari, 1998}
\bibcite{amari1998natural1}{Amari and Douglas, 1998}
\bibcite{antos2008fitted}{Antos et~al., 2008}
\bibcite{auer2002using}{Auer, 2002}
\bibcite{auer2002finite}{Auer et~al., 2002}
\bibcite{auer2007logarithmic}{Auer and Ortner, 2007}
\bibcite{auer2010ucb}{Auer and Ortner, 2010}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{97}{chapter*.25}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{baird1993advantage}{Baird~III, 1993}
\bibcite{baxter2001infinite}{Baxter and Bartlett, 2001}
\bibcite{bellemare2016unifying}{Bellemare et~al., 2016}
\bibcite{blei2017variational}{Blei et~al., 2017}
\bibcite{blundell2015weight}{Blundell et~al., 2015}
\bibcite{boucheron2013concentration}{Boucheron et~al., 2013}
\bibcite{brafman2002r}{Brafman and Tennenholtz, 2002}
\bibcite{brockman2016openai}{Brockman et~al., 2016}
\bibcite{bubeck2012regret}{Bubeck et~al., 2012}
\bibcite{bubeck2013bandits}{Bubeck et~al., 2013}
\bibcite{bubeck2011x}{Bubeck et~al., 2011}
\bibcite{cesa2017boltzmann}{Cesa-Bianchi et~al., 2017}
\bibcite{chentanez2005intrinsically}{Chentanez et~al., 2005}
\bibcite{choshen2018dora}{Choshen et~al., 2018}
\bibcite{cochran2007sampling}{Cochran, 2007}
\bibcite{cortes2010learning}{Cortes et~al., 2010}
\bibcite{dayan1997using}{Dayan and Hinton, 1997}
\bibcite{degris2012off}{Degris et~al., 2012}
\bibcite{deisenroth2013survey}{Deisenroth et~al., 2013}
\bibcite{baselines}{Dhariwal et~al., 2017}
\bibcite{dorato1995linear}{Dorato et~al., 1995}
\bibcite{duan2016benchmarking}{Duan et~al., 2016}
\bibcite{espeholt2018impala}{Espeholt et~al., 2018}
\bibcite{garivier2011kl}{Garivier and Capp{\'e}, 2011}
\bibcite{gil2013renyi}{Gil et~al., 2013}
\bibcite{glynn1990likelihood}{Glynn, 1990}
\bibcite{goodfellow2016deep}{Goodfellow et~al., 2016}
\bibcite{grondman2012survey}{Grondman et~al., 2012}
\bibcite{haarnoja2017reinforcement}{Haarnoja et~al., 2017}
\bibcite{haarnoja2018soft}{Haarnoja et~al., 2018}
\bibcite{hershey2007approximating}{Hershey and Olsen, 2007}
\bibcite{houthooft2016vime}{Houthooft et~al., 2016}
\bibcite{ionides2008truncated}{Ionides, 2008}
\bibcite{kearns2002near}{Kearns and Singh, 2002}
\bibcite{kimura1999efficient}{Kimura, 1999}
\bibcite{kleinberg2008multi}{Kleinberg et~al., 2008}
\bibcite{kleinberg2013bandits}{Kleinberg et~al., 2013}
\bibcite{kleinberg2005nearly}{Kleinberg, 2005}
\bibcite{kober2009policy}{Kober and Peters, 2009}
\bibcite{kong1992note}{Kong, 1992}
\bibcite{kupcsik2013data}{Kupcsik et~al., 2013}
\bibcite{lai1985asymptotically}{Lai and Robbins, 1985}
\bibcite{lange2012batch}{Lange et~al., 2012}
\bibcite{lattimore2019bandit}{Lattimore and Szepesv\'{a}ri, 2019}
\bibcite{lopes2012exploration}{Lopes et~al., 2012}
\bibcite{magureanu2014lipschitz}{Magureanu et~al., 2014}
\bibcite{martino2017effective}{Martino et~al., 2017}
\bibcite{metelli2018policy}{Metelli et~al., 2018}
\bibcite{mnih2016asynchronous}{Mnih et~al., 2016}
\bibcite{more1994line}{Mor{\'e} and Thuente, 1994}
\bibcite{oord2016pixel}{Oord et~al., 2016}
\bibcite{osband2016deep}{Osband et~al., 2016}
\bibcite{osband2013more}{Osband et~al., 2013}
\bibcite{osband2015bootstrapped}{Osband and Van~Roy, 2015}
\bibcite{osband2017posterior}{Osband and Van~Roy, 2017}
\bibcite{ostrovski2017count}{Ostrovski et~al., 2017}
\bibcite{oudeyer2007intrinsic}{Oudeyer et~al., 2007}
\bibcite{mcbook}{Owen, 2013}
\bibcite{peters2008reinforcement}{Peters and Schaal, 2008}
\bibcite{puterman2014markov}{Puterman, 2014}
\bibcite{renyi1961measures}{R{\'{e}}nyi, 1961}
\bibcite{rummery1994line}{Rummery and Niranjan, 1994}
\bibcite{russo2013eluder}{Russo and Van~Roy, 2013}
\bibcite{russo2018tutorial}{Russo et~al., 2018}
\bibcite{sallans2004reinforcement}{Sallans and Hinton, 2004}
\bibcite{schmidhuber1991possibility}{Schmidhuber, 1991}
\bibcite{schulman2015trust}{Schulman et~al., 2015}
\bibcite{scott2015multivariate}{Scott, 2015}
\bibcite{sehnke2008policy}{Sehnke et~al., 2008}
\bibcite{sehnke2010parameter}{Sehnke et~al., 2010}
\bibcite{silver2014deterministic}{Silver et~al., 2014}
\bibcite{srinivas2010gaussian}{Srinivas et~al., 2010}
\bibcite{still2012information}{Still and Precup, 2012}
\bibcite{strens2000bayesian}{Strens, 2000}
\bibcite{sutton1988learning}{Sutton, 1988}
\bibcite{sutton1991dyna}{Sutton, 1991}
\bibcite{sutton2018reinforcement}{Sutton and Barto, 2018}
\bibcite{sutton2000policy}{Sutton et~al., 2000}
\bibcite{tang2017exploration}{Tang et~al., 2017}
\bibcite{thompson1933likelihood}{Thompson, 1933}
\bibcite{thrun1992efficient}{Thrun, 1992}
\bibcite{tornio2006variational}{Tornio and Raiko, 2006}
\bibcite{veach_optimally_1995}{Veach and Guibas, 1995}
\bibcite{watkins1989learning}{Watkins, 1989}
\bibcite{wawrzynski2005intensive}{Wawrzy{\'n}ski, 2005}
\bibcite{whitehead1991study}{Whitehead and Ballard, 1991}
\bibcite{williams2006gaussian}{Williams and Rasmussen, 2006}
\bibcite{williams1992simple}{Williams, 1992}
\bibcite{zhao2011analysis}{Zhao et~al., 2011}
\bibcite{ziebart2008maximum}{Ziebart et~al., 2008}
\providecommand\@xdylanguage[2]{}
\@xdylanguage{acronym}{english}
\providecommand\@gls@codepage[2]{}
\@gls@codepage{acronym}{utf8}
