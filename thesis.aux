\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{acronym}{alg}{acr}{acn}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesis.ist}
\@glsorder{word}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{lai1985asymptotically}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Preliminaries}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Preliminaries}{{1}{1}{Preliminaries}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Multi Armed Bandits}{1}{section.1.1}}
\newlabel{sec:mab}{{1.1}{1}{Multi Armed Bandits}{section.1.1}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {definition}{\numberline {1.1.1}Definition}{2}{definition.1.1.1}}
\@writefile{loe}{\contentsline {definition}{\numberline {1.1.2}Definition}{2}{definition.1.1.2}}
\newlabel{def:immediateregret}{{1.1.2}{2}{}{definition.1.1.2}{}}
\citation{lattimore2019bandit}
\@writefile{loe}{\contentsline {definition}{\numberline {1.1.3}Definition}{3}{definition.1.1.3}}
\newlabel{def:regret}{{1.1.3}{3}{}{definition.1.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Exploration and exploitation}{3}{subsection.1.1.1}}
\newlabel{eedilemma}{{1.1.1}{3}{Exploration and exploitation}{subsection.1.1.1}{}}
\citation{lattimore2019bandit}
\citation{lattimore2019bandit}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Stochastic Bandits With Finitely Many Arms}{4}{subsection.1.1.2}}
\newlabel{finiteMABs}{{1.1.2}{4}{Stochastic Bandits With Finitely Many Arms}{subsection.1.1.2}{}}
\newlabel{eq:averagereward}{{1.3}{4}{Stochastic Bandits With Finitely Many Arms}{equation.1.1.3}{}}
\newlabel{thmt@@regretETC@data}{{\def \theequation {1.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )1.1.\@arabic {\c@equation }}\setcounter {equation}{3}}{4}{Stochastic Bandits With Finitely Many Arms}{algorithm.1.1}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {1.1.1}Theorem}{4}{theorem.1.1.1}}
\newlabel{thmt@@regretETC}{{1.1.1}{4}{}{theorem.1.1.1}{}}
\newlabel{th:regretETC}{{1.1.1}{4}{}{theorem.1.1.1}{}}
\citation{agrawal1995continuum}
\citation{magureanu2014lipschitz}
\citation{bubeck2011x}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1.1}{\ignorespaces Explore-then-commit\relax }}{5}{algorithm.1.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:explorethencommit}{{1.1}{5}{Explore-then-commit\relax }{algorithm.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}$\mathcal  {X}$-armed bandits}{5}{subsection.1.1.3}}
\newlabel{sub:xarmedbandits}{{1.1.3}{5}{$\mathcal {X}$-armed bandits}{subsection.1.1.3}{}}
\citation{puterman2014markov}
\citation{sutton2018reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Markov Decision Processes}{6}{section.1.2}}
\@writefile{loe}{\contentsline {definition}{\numberline {1.2.1}Definition}{6}{definition.1.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Interaction protocol for Markov decision processes\relax }}{7}{figure.caption.2}}
\newlabel{fig:MDP}{{1.1}{7}{Interaction protocol for Markov decision processes\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Policies}{8}{subsection.1.2.1}}
\@writefile{loe}{\contentsline {definition}{\numberline {1.2.2}Definition}{8}{definition.1.2.2}}
\@writefile{loe}{\contentsline {remark}{\numberline {1.2.1}Remark}{8}{remark.1.2.1}}
\citation{sutton2000policy}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Performance}{9}{subsection.1.2.2}}
\newlabel{eq:Jstartstate}{{1.6}{9}{Performance}{equation.1.2.6}{}}
\newlabel{eq:ssdistribution}{{1.7}{9}{Performance}{equation.1.2.7}{}}
\citation{baird1993advantage}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Value functions}{10}{subsection.1.2.3}}
\newlabel{eq:BellmanV}{{1.11}{10}{Value functions}{equation.1.2.11}{}}
\newlabel{eq:BellmanQ}{{1.13}{10}{Value functions}{equation.1.2.13}{}}
\citation{sutton2018reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Reinforcement Learning}{11}{section.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Problem formulation}{11}{subsection.1.3.1}}
\citation{puterman2014markov}
\citation{sutton2018reinforcement}
\newlabel{eq:optimalpolicy}{{1.15}{12}{Problem formulation}{equation.1.3.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Taxonomy}{12}{subsection.1.3.2}}
\citation{sutton1991dyna}
\citation{kupcsik2013data}
\citation{watkins1989learning}
\citation{rummery1994line}
\citation{williams1992simple}
\citation{watkins1989learning}
\citation{degris2012off}
\citation{rummery1994line}
\citation{sutton1988learning}
\citation{williams1992simple}
\citation{baxter2001infinite}
\citation{sutton2018reinforcement}
\citation{antos2008fitted}
\citation{grondman2012survey}
\citation{lange2012batch}
\citation{more1994line}
\citation{deisenroth2013survey}
\citation{sutton2000policy}
\citation{dayan1997using}
\citation{kober2009policy}
\citation{still2012information}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Policy Search}{15}{section.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Overview}{15}{subsection.1.4.1}}
\newlabel{subsec:PSoverview}{{1.4.1}{15}{Overview}{subsection.1.4.1}{}}
\newlabel{eq:PSproblem}{{1.16}{15}{Overview}{equation.1.4.16}{}}
\citation{deisenroth2013survey}
\citation{deisenroth2013survey}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A taxonomy of \gls {PS} methods \cite  {deisenroth2013survey}\relax }}{16}{figure.caption.3}}
\newlabel{fig:PStaxonomy}{{1.2}{16}{A taxonomy of \gls {PS} methods \cite {deisenroth2013survey}\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Policy gradient}{16}{subsection.1.4.2}}
\citation{sutton2000policy}
\newlabel{eq:paramsupdate}{{1.20}{17}{Policy gradient}{equation.1.4.20}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {1.4.1}Theorem}{17}{theorem.1.4.1}}
\newlabel{th:PGtheorem}{{1.4.1}{17}{}{theorem.1.4.1}{}}
\newlabel{eq:PGtheorem}{{1.21}{17}{}{equation.1.4.21}{}}
\citation{williams1992simple}
\citation{sutton2000policy}
\citation{amari1998natural1}
\newlabel{eq:reinforcetrick}{{1.21}{18}{Policy gradient}{equation.1.4.21}{}}
\newlabel{eq:trajectoryPG}{{1.24}{18}{Policy gradient}{equation.1.4.24}{}}
\newlabel{eq:logpolicyestimate}{{1.26}{18}{Policy gradient}{equation.1.4.26}{}}
\citation{amari1998natural1}
\citation{amari1998natural2}
\citation{peters2008reinforcement}
\citation{glynn1990likelihood}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Policy gradient estimation}{19}{subsection.1.4.3}}
\citation{williams1992simple}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1.2}{\ignorespaces Generic \gls {PG} algorithm\relax }}{20}{algorithm.1.2}}
\newlabel{alg:PG}{{1.2}{20}{Generic \gls {PG} algorithm\relax }{algorithm.1.2}{}}
\newlabel{step:PGestimation}{{5}{20}{Generic \gls {PG} algorithm\relax }{algorithm.1.2}{}}
\citation{williams1992simple}
\citation{peters2008reinforcement}
\citation{zhao2011analysis}
\newlabel{eq:PGbaseline}{{1.29}{21}{Policy gradient estimation}{equation.1.4.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Algorithms}{21}{subsection.1.4.4}}
\newlabel{subsec:algorithms}{{1.4.4}{21}{Algorithms}{subsection.1.4.4}{}}
\newlabel{eq:REINFORCE}{{1.30}{21}{Algorithms}{equation.1.4.30}{}}
\citation{baxter2001infinite}
\citation{sutton2000policy}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1.3}{\ignorespaces Episodic REINFORCE with component-wise optimal baseline.\relax }}{22}{algorithm.1.3}}
\newlabel{alg:REINFORCE}{{1.3}{22}{Episodic REINFORCE with component-wise optimal baseline.\relax }{algorithm.1.3}{}}
\citation{peters2008reinforcement}
\citation{zhao2011analysis}
\citation{sehnke2008policy}
\citation{sehnke2010parameter}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1.4}{\ignorespaces Episodic \gls {PGPE}\relax }}{24}{algorithm.1.4}}
\newlabel{alg:PGPE}{{1.4}{24}{Episodic \gls {PGPE}\relax }{algorithm.1.4}{}}
\citation{cochran2007sampling}
\citation{mcbook}
\citation{mcbook}
\citation{veach_optimally_1995}
\citation{veach_optimally_1995}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Multiple Importance Sampling}{25}{section.1.5}}
\newlabel{sec:mis}{{1.5}{25}{Multiple Importance Sampling}{section.1.5}{}}
\newlabel{eq:ise}{{1.37}{25}{Multiple Importance Sampling}{equation.1.5.37}{}}
\newlabel{eq:mise}{{1.38}{25}{Multiple Importance Sampling}{equation.1.5.38}{}}
\citation{veach_optimally_1995}
\citation{renyi1961measures}
\citation{cortes2010learning}
\citation{metelli2018policy}
\newlabel{eq:bhw}{{1.39}{26}{Multiple Importance Sampling}{equation.1.5.39}{}}
\newlabel{eq:bhe}{{1.40}{26}{Multiple Importance Sampling}{equation.1.5.40}{}}
\newlabel{eq:renyi}{{1.41}{26}{Multiple Importance Sampling}{equation.1.5.41}{}}
\newlabel{thmt@@misevarbound@data}{{\def \theequation {1.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )1.5.\@arabic {\c@equation }}\setcounter {equation}{43}}{26}{Multiple Importance Sampling}{equation.1.5.43}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {1.5.1}Lemma}{26}{lemma.1.5.1}}
\newlabel{thmt@@misevarbound}{{1.5.1}{26}{}{lemma.1.5.1}{}}
\newlabel{lem:misevarbound}{{1.5.1}{26}{}{lemma.1.5.1}{}}
\citation{thrun1992efficient}
\citation{whitehead1991study}
\citation{thrun1992efficient}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Exploration Techniques}{28}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:sota}{{2}{28}{Exploration Techniques}{chapter.2}{}}
\citation{lattimore2019bandit}
\citation{auer2002finite}
\citation{cesa2017boltzmann}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Exploration in Multi Armed Bandits}{29}{section.2.1}}
\newlabel{sec:expinmab}{{2.1}{29}{Exploration in Multi Armed Bandits}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Undirected Exploration}{29}{subsection.2.1.1}}
\citation{lai1985asymptotically}
\citation{agrawal1995continuum}
\citation{auer2002finite}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Count-based exploration and Upper Confidence Bound}{30}{subsection.2.1.2}}
\newlabel{sebsec:count&UCB}{{2.1.2}{30}{Count-based exploration and Upper Confidence Bound}{subsection.2.1.2}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {definition}{\numberline {2.1.1}Definition}{30}{definition.2.1.1}}
\newlabel{def:subgaussianity}{{2.1.1}{30}{}{definition.2.1.1}{}}
\citation{lattimore2019bandit}
\citation{auer2002finite}
\citation{agrawal1995continuum}
\@writefile{loe}{\contentsline {theorem}{\numberline {2.1.1}Theorem}{31}{theorem.2.1.1}}
\@writefile{loe}{\contentsline {corollary}{\numberline {2.1.1}Corollary}{31}{corollary.2.1.1}}
\newlabel{cor:subgaussian}{{2.1.1}{31}{}{corollary.2.1.1}{}}
\newlabel{eq:ucb}{{2.4}{31}{Count-based exploration and Upper Confidence Bound}{equation.2.1.4}{}}
\citation{auer2002finite}
\citation{auer2010ucb}
\citation{garivier2011kl}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.1}{\ignorespaces \gls {UCB}($\delta $) algorithm\relax }}{32}{algorithm.2.1}}
\newlabel{alg:ucb}{{2.1}{32}{\gls {UCB}($\delta $) algorithm\relax }{algorithm.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Optimism in the Face of Uncertainty}{32}{subsection.2.1.3}}
\citation{bubeck2011x}
\citation{kleinberg2005nearly}
\citation{kleinberg2008multi}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4} Hierarchical Optimistic Optimization}{33}{subsection.2.1.4}}
\newlabel{sub:hoo}{{2.1.4}{33}{Hierarchical Optimistic Optimization}{subsection.2.1.4}{}}
\@writefile{loe}{\contentsline {definition}{\numberline {2.1.2}Definition}{34}{definition.2.1.2}}
\newlabel{def:treeofcoverings}{{2.1.2}{34}{}{definition.2.1.2}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {2.1.1}Remark}{34}{remark.2.1.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.2}{\ignorespaces \gls {HOO} algorithm\relax }}{35}{algorithm.2.2}}
\newlabel{alg:hoo}{{2.2}{35}{\gls {HOO} algorithm\relax }{algorithm.2.2}{}}
\citation{bubeck2011x}
\citation{thompson1933likelihood}
\citation{russo2013eluder}
\@writefile{loe}{\contentsline {assumption}{\numberline {2.1.1}Assumption}{36}{assumption.2.1.1}}
\newlabel{eq:weaklipschitz}{{2.12}{36}{}{equation.2.1.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Posterior Sampling}{36}{subsection.2.1.5}}
\citation{agrawal2013further}
\citation{bubeck2012regret}
\citation{russo2018tutorial}
\citation{srinivas2010gaussian}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.6}Gaussian Process Upper Confidence Bound}{37}{subsection.2.1.6}}
\citation{srinivas2010gaussian}
\citation{williams2006gaussian}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.3}{\ignorespaces \gls {TS} for Bernoulli MAB with Beta priors\relax }}{38}{algorithm.2.3}}
\newlabel{alg:bernoulliTS}{{2.3}{38}{\gls {TS} for Bernoulli MAB with Beta priors\relax }{algorithm.2.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.4}{\ignorespaces \gls {GPUCB}\relax }}{39}{algorithm.2.4}}
\newlabel{alg:gpucb}{{2.4}{39}{\gls {GPUCB}\relax }{algorithm.2.4}{}}
\newlabel{eq:gpucbrule}{{3}{39}{\gls {GPUCB}\relax }{algorithm.2.4}{}}
\citation{sutton2018reinforcement}
\citation{thrun1992efficient}
\citation{cesa2017boltzmann}
\citation{sallans2004reinforcement}
\citation{kappen2005path}
\citation{ziebart2008maximum}
\citation{haarnoja2017reinforcement}
\citation{haarnoja2017reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Exploration in Reinforcement Learning}{40}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Undirected Exploration}{40}{subsection.2.2.1}}
\citation{haarnoja2017reinforcement}
\citation{haarnoja2018soft}
\citation{kearns2002near}
\citation{brafman2002r}
\citation{auer2007logarithmic}
\citation{bellemare2016unifying}
\citation{tang2017exploration}
\citation{ostrovski2017count}
\citation{choshen2018dora}
\citation{bellemare2016unifying}
\citation{ostrovski2017count}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Count-based exploration and Intrinsic Motivation}{41}{subsection.2.2.2}}
\citation{ostrovski2017count}
\citation{oord2016pixel}
\citation{lopes2012exploration}
\citation{oudeyer2007intrinsic}
\citation{chentanez2005intrinsically}
\citation{schmidhuber1991possibility}
\citation{bellemare2016unifying}
\citation{houthooft2016vime}
\citation{blei2017variational}
\citation{blundell2015weight}
\citation{houthooft2016vime}
\citation{strens2000bayesian}
\citation{osband2013more}
\citation{osband2015bootstrapped}
\citation{osband2016deep}
\citation{strens2000bayesian}
\citation{osband2017posterior}
\newlabel{eq:augmentedreward}{{2.29}{45}{Count-based exploration and Intrinsic Motivation}{equation.2.2.29}{}}
\newlabel{eq:elb}{{2.30}{45}{Count-based exploration and Intrinsic Motivation}{equation.2.2.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Posterior Sampling}{45}{subsection.2.2.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.5}{\ignorespaces \gls {VIME}\relax }}{46}{algorithm.2.5}}
\newlabel{alg:VIME}{{2.5}{46}{\gls {VIME}\relax }{algorithm.2.5}{}}
\citation{metelli2018policy}
\citation{ionides2008truncated}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Optimistic Policy Optimization via Multiple Importance Sampling}{47}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:core}{{3}{47}{Optimistic Policy Optimization via Multiple Importance Sampling}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Robust Importance Sampling Estimation}{47}{section.3.1}}
\newlabel{sec:robust}{{3.1}{47}{Robust Importance Sampling Estimation}{section.3.1}{}}
\newlabel{eq:truncatedise}{{3.1}{48}{Robust Importance Sampling Estimation}{equation.3.1.1}{}}
\newlabel{eq:truncatedmise}{{3.2}{48}{Robust Importance Sampling Estimation}{equation.3.1.2}{}}
\newlabel{thmt@@truncatedbias@data}{{\def \theequation {3.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )3.1.\@arabic {\c@equation }}\setcounter {equation}{2}}{48}{Robust Importance Sampling Estimation}{equation.3.1.2}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {lemma}{\numberline {3.1.1}Lemma}{48}{lemma.3.1.1}}
\newlabel{thmt@@truncatedbias}{{3.1.1}{48}{}{lemma.3.1.1}{}}
\newlabel{lem:truncatedbias}{{3.1.1}{48}{}{lemma.3.1.1}{}}
\newlabel{eq:biastruncated}{{3.3}{48}{}{equation.3.1.3}{}}
\newlabel{eq:variancetruncated}{{3.4}{48}{}{equation.3.1.4}{}}
\citation{bubeck2013bandits}
\citation{bubeck2013bandits}
\citation{ionides2008truncated}
\newlabel{thmt@@thrucatedconcentration@data}{{\def \theequation {3.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )3.1.\@arabic {\c@equation }}\setcounter {equation}{4}}{49}{Robust Importance Sampling Estimation}{equation.3.1.4}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {3.1.1}Theorem}{49}{theorem.3.1.1}}
\newlabel{thmt@@thrucatedconcentration}{{3.1.1}{49}{}{theorem.3.1.1}{}}
\newlabel{lem:thrucatedconcentration}{{3.1.1}{49}{}{theorem.3.1.1}{}}
\newlabel{eq:1.1}{{3.5}{49}{}{equation.3.1.5}{}}
\newlabel{eq:1.2}{{3.6}{49}{}{equation.3.1.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Problem Formalization}{49}{section.3.2}}
\newlabel{sec:problem}{{3.2}{49}{Problem Formalization}{section.3.2}{}}
\citation{kleinberg2013bandits}
\newlabel{eq:theproblem}{{3.7}{50}{Problem Formalization}{equation.3.2.7}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {3.2.1}Remark}{50}{remark.3.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Algorithms}{51}{section.3.3}}
\newlabel{sec:algo}{{3.3}{51}{Algorithms}{section.3.3}{}}
\newlabel{eq:wcmu}{{3.8}{51}{Algorithms}{equation.3.3.8}{}}
\newlabel{eq:optimistindex}{{3.9}{51}{Algorithms}{equation.3.3.9}{}}
\citation{srinivas2010gaussian}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.1}{\ignorespaces \gls {OPTIMIST}\relax }}{52}{algorithm.3.1}}
\newlabel{alg:1}{{3.1}{52}{\gls {OPTIMIST}\relax }{algorithm.3.1}{}}
\newlabel{line:sampling}{{2}{52}{\gls {OPTIMIST}\relax }{algorithm.3.1}{}}
\newlabel{line:optstep}{{4}{52}{\gls {OPTIMIST}\relax }{algorithm.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Regret Analysis}{52}{section.3.4}}
\newlabel{sec:regret}{{3.4}{52}{Regret Analysis}{section.3.4}{}}
\newlabel{eq:inregret}{{3.10}{52}{Regret Analysis}{equation.3.4.10}{}}
\citation{srinivas2010gaussian}
\citation{bubeck2013bandits}
\newlabel{eq:regret}{{3.11}{53}{Regret Analysis}{equation.3.4.11}{}}
\newlabel{thmt@@boundrenyi@data}{{\def \theequation {3.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )3.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{53}{Regret Analysis}{equation.3.4.11}{}}
\@writefile{loe}{\contentsline {assumption}{\numberline {3.4.1}Assumption}{53}{assumption.3.4.1}}
\newlabel{thmt@@boundrenyi}{{3.4.1}{53}{}{assumption.3.4.1}{}}
\newlabel{ass:boundrenyi}{{3.4.1}{53}{}{assumption.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Discrete arm set}{53}{subsection.3.4.1}}
\newlabel{thmt@@regretdiscrete@data}{{\def \theequation {3.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )3.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{53}{Discrete arm set}{subsection.3.4.1}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {3.4.1}Theorem}{53}{theorem.3.4.1}}
\newlabel{thmt@@regretdiscrete}{{3.4.1}{53}{}{theorem.3.4.1}{}}
\newlabel{th:regretdiscrete}{{3.4.1}{53}{}{theorem.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Compact arm set}{54}{subsection.3.4.2}}
\newlabel{thmt@@lipschitz@data}{{\def \theequation {3.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )3.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{54}{Compact arm set}{subsection.3.4.2}{}}
\@writefile{loe}{\contentsline {assumption}{\numberline {3.4.2}Assumption}{54}{assumption.3.4.2}}
\newlabel{thmt@@lipschitz}{{3.4.2}{54}{}{assumption.3.4.2}{}}
\newlabel{ass:lipschitz}{{3.4.2}{54}{}{assumption.3.4.2}{}}
\newlabel{thmt@@lipschitzpol@data}{{\def \theequation {3.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )3.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{54}{Compact arm set}{assumption.3.4.2}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {3.4.1}Lemma}{54}{lemma.3.4.1}}
\newlabel{thmt@@lipschitzpol}{{3.4.1}{54}{}{lemma.3.4.1}{}}
\newlabel{lem:lispschitzpol}{{3.4.1}{54}{}{lemma.3.4.1}{}}
\newlabel{eq:lp1}{{3.12}{54}{}{equation.3.4.12}{}}
\newlabel{eq:lp2}{{3.13}{54}{}{equation.3.4.13}{}}
\newlabel{thmt@@regretcompact@data}{{\def \theequation {3.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )3.4.\@arabic {\c@equation }}\setcounter {equation}{13}}{54}{Compact arm set}{equation.3.4.13}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {3.4.2}Theorem}{54}{theorem.3.4.2}}
\newlabel{thmt@@regretcompact}{{3.4.2}{54}{}{theorem.3.4.2}{}}
\newlabel{th:regretcompact}{{3.4.2}{54}{}{theorem.3.4.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.2}{\ignorespaces \gls {OPTIMIST}2\relax }}{55}{algorithm.3.2}}
\newlabel{alg:2}{{3.2}{55}{\gls {OPTIMIST}2\relax }{algorithm.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Discretization}{55}{subsection.3.4.3}}
\newlabel{thmt@@regretdiscretized@data}{{\def \theequation {3.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )3.4.\@arabic {\c@equation }}\setcounter {equation}{13}}{55}{Discretization}{subsection.3.4.3}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {3.4.3}Theorem}{55}{theorem.3.4.3}}
\newlabel{thmt@@regretdiscretized}{{3.4.3}{55}{}{theorem.3.4.3}{}}
\newlabel{th:regretdiscretized}{{3.4.3}{55}{}{theorem.3.4.3}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {3.4.1}Remark}{56}{remark.3.4.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Numerical Simulations}{57}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:experiments}{{4}{57}{Numerical Simulations}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Practical Aspects}{57}{section.4.1}}
\newlabel{sec:practical}{{4.1}{57}{Practical Aspects}{section.4.1}{}}
\citation{gil2013renyi}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Divergence Between Gaussian Multivariate Distributions}{58}{subsection.4.1.1}}
\newlabel{thmt@@armonic@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.1.\@arabic {\c@equation }}\setcounter {equation}{2}}{58}{Divergence Between Gaussian Multivariate Distributions}{subsection.4.1.1}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.1.1}Theorem}{58}{theorem.4.1.1}}
\newlabel{thmt@@armonic}{{4.1.1}{58}{}{theorem.4.1.1}{}}
\newlabel{th:armonic}{{4.1.1}{58}{}{theorem.4.1.1}{}}
\citation{gil2013renyi}
\citation{gil2013renyi}
\newlabel{eq:gaussianrenyi}{{4.4}{59}{Divergence Between Gaussian Multivariate Distributions}{equation.4.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Uniformly Bounded R\IeC {\'e}nyi divergence}{59}{subsection.4.1.2}}
\newlabel{subsec:boundrenyi}{{4.1.2}{59}{Uniformly Bounded Rényi divergence}{subsection.4.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Action-based setting}{59}{section.4.2}}
\citation{martino2017effective}
\citation{kong1992note}
\citation{kong1992note}
\citation{peters2008reinforcement}
\citation{dorato1995linear}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Linear Quadratic Gaussian Regulator}{61}{section.4.3}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Environmental coefficients (left-side), task coefficients (center) and \gls {OPTIMIST} input parameters (left-side) for the \gls {LQG} experiments.\relax }}{62}{table.caption.4}}
\newlabel{tab:LQGcoeff}{{4.1}{62}{Environmental coefficients (left-side), task coefficients (center) and \gls {OPTIMIST} input parameters (left-side) for the \gls {LQG} experiments.\relax }{table.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Cumulative regret in the \gls {LQG} experiment, comparing \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning the mean hyperparameter only. (30 runs, 95\% c.i.)\relax }}{62}{figure.caption.5}}
\newlabel{fig:LQGcomparison}{{4.1}{62}{Cumulative regret in the \gls {LQG} experiment, comparing \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning the mean hyperparameter only. (30 runs, 95\% c.i.)\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Gain only}{62}{subsection.4.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The gain parameter $\mu $ selected at each iteration of \gls {GPUCB}(left) and \gls {OPTIMIST}(right) in the \gls {LQG} experiment.\relax }}{63}{figure.caption.6}}
\newlabel{fig:LQGmu}{{4.2}{63}{The gain parameter $\mu $ selected at each iteration of \gls {GPUCB}(left) and \gls {OPTIMIST}(right) in the \gls {LQG} experiment.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Mean return of arms $\mu \in [-0.9,-0,5]$, calculated by averaging the return collected over 2000 trajectories for each arm pulled in the \gls {LQG} experiment.\relax }}{63}{figure.caption.7}}
\newlabel{fig:LQGoptimalgain}{{4.3}{63}{Mean return of arms $\mu \in [-0.9,-0,5]$, calculated by averaging the return collected over 2000 trajectories for each arm pulled in the \gls {LQG} experiment.\relax }{figure.caption.7}{}}
\@writefile{tdo}{\contentsline {todo}{spiegare cosa succede se $\sigma $ \IeC {\`e} troppo piccola e i bracci non condividono informazione}{63}{section*.8}}
\pgfsyspdfmark {pgfid2}{25097606}{21350693}
\pgfsyspdfmark {pgfid5}{35251789}{21367617}
\pgfsyspdfmark {pgfid6}{36480589}{21096741}
\citation{brockman2016openai}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Gain and standard deviation}{64}{subsection.4.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Continuous Mountain Car}{64}{section.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Cumulative regret in the \gls {LQG} experiment, comparing \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning both the mean and the standard deviation hyperparameters only. (30 runs, 95\% c.i.)\relax }}{65}{figure.caption.9}}
\newlabel{fig:LQGcomparisonVar}{{4.4}{65}{Cumulative regret in the \gls {LQG} experiment, comparing \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning both the mean and the standard deviation hyperparameters only. (30 runs, 95\% c.i.)\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Graphical representation of the Mountain Car problem.\relax }}{65}{figure.caption.10}}
\newlabel{fig:MC}{{4.5}{65}{Graphical representation of the Mountain Car problem.\relax }{figure.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Mountain Car experiment.\relax }}{65}{table.caption.11}}
\newlabel{tab:MCcoeff}{{4.2}{65}{Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Mountain Car experiment.\relax }{table.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Cumulative regret in the \gls {LQG} experiment, comparing \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning both the mean and the standard deviation hyperparameters only. (30 runs, 95\% c.i.)\relax }}{66}{figure.caption.12}}
\newlabel{fig:MCcomparison}{{4.6}{66}{Cumulative regret in the \gls {LQG} experiment, comparing \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning both the mean and the standard deviation hyperparameters only. (30 runs, 95\% c.i.)\relax }{figure.caption.12}{}}
\citation{metelli2018policy}
\citation{scott2015multivariate}
\citation{scott2015multivariate}
\citation{scott2015multivariate}
\@writefile{loe}{\contentsline {remark}{\numberline {4.4.1}Remark}{67}{remark.4.4.1}}
\newlabel{rk:undiscounted}{{4.4.1}{67}{}{remark.4.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Gaussian kernel density estimation \cite  {scott2015multivariate} of the probability of the two-dimensional learnable mean $\bm  {\mu }$ to be pulled by either \gls {PGPE} (left) or \gls {OPTIMIST} (right).\relax }}{68}{figure.caption.13}}
\newlabel{fig:MCgain}{{4.7}{68}{Gaussian kernel density estimation \cite {scott2015multivariate} of the probability of the two-dimensional learnable mean $\vmu $ to be pulled by either \gls {PGPE} (left) or \gls {OPTIMIST} (right).\relax }{figure.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Mountain Car experiment.\relax }}{68}{table.caption.14}}
\newlabel{tab:granularity}{{4.3}{68}{Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Mountain Car experiment.\relax }{table.caption.14}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {4.4.2}Remark}{68}{remark.4.4.2}}
\newlabel{rk:discretization}{{4.4.2}{68}{}{remark.4.4.2}{}}
\citation{tornio2006variational}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Graphical representation of the Inverted Pendulum task.\relax }}{69}{figure.caption.15}}
\newlabel{fig:invpend}{{4.8}{69}{Graphical representation of the Inverted Pendulum task.\relax }{figure.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Inverted Pendulum experiment.\relax }}{69}{table.caption.16}}
\newlabel{tab:IPcoeff}{{4.4}{69}{Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Inverted Pendulum experiment.\relax }{table.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Inverted Pendulum}{69}{section.4.5}}
\citation{kimura1999efficient}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces The hyperpolicy mean parameter selected at each iteration of \gls {OPTIMIST} in the Inverted Pendulum experiment.\relax }}{71}{figure.caption.17}}
\newlabel{fig:IPmu1}{{4.9}{71}{The hyperpolicy mean parameter selected at each iteration of \gls {OPTIMIST} in the Inverted Pendulum experiment.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Truncated \gls {MIS} estimator (left) and exploration bonus (right) of the arms selected by \gls {OPTIMIST} at each iteration of the Inverted Pendulum experiment.\relax }}{72}{figure.caption.18}}
\newlabel{fig:IPbound}{{4.10}{72}{Truncated \gls {MIS} estimator (left) and exploration bonus (right) of the arms selected by \gls {OPTIMIST} at each iteration of the Inverted Pendulum experiment.\relax }{figure.caption.18}{}}
\citation{metelli2018policy}
\@writefile{toc}{\contentsline {chapter}{Appendices}{73}{section*.19}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Proofs}{73}{Appendix.1.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:proof}{{A}{73}{Proofs}{Appendix.1.A}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {lemma}{\numberline {1.5.1}Lemma}{73}{lemma.dummy.41}}
\newlabel{p:misevarboundline2}{{A.1}{74}{Proofs}{equation.1.A.0.1}{}}
\newlabel{p:misevarboundline5}{{A.2}{74}{Proofs}{equation.1.A.0.2}{}}
\newlabel{eq:expectationdecomposition}{{A.3}{74}{Proofs}{equation.1.A.0.3}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {3.1.1}Lemma}{74}{lemma.dummy.43}}
\newlabel{p:truncatedbias1}{{A.5}{75}{Proofs}{equation.1.A.0.5}{}}
\newlabel{p:truncatedbias2}{{A.6}{75}{Proofs}{equation.1.A.0.6}{}}
\newlabel{p:truncatedbias3}{{A.7}{75}{Proofs}{equation.1.A.0.7}{}}
\citation{boucheron2013concentration}
\newlabel{p:truncatedbias4}{{A.8}{76}{Proofs}{equation.1.A.0.8}{}}
\newlabel{p:truncatedbias5}{{A.9}{76}{Proofs}{equation.1.A.0.9}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {3.1.1}Theorem}{76}{theorem.dummy.45}}
\newlabel{p:thrucatedconcentration1}{{A.11}{77}{Proofs}{equation.1.A.0.11}{}}
\newlabel{p:thrucatedconcentration2}{{A.12}{77}{Proofs}{equation.1.A.0.12}{}}
\newlabel{p:thrucatedconcentration3}{{A.13}{77}{Proofs}{equation.1.A.0.13}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {3.4.1}Theorem}{77}{theorem.dummy.47}}
\newlabel{aux:1}{{A.15}{78}{Proofs}{equation.1.A.0.15}{}}
\newlabel{pp:1}{{A.16}{78}{Proofs}{equation.1.A.0.16}{}}
\newlabel{pp:2}{{A.17}{78}{Proofs}{equation.1.A.0.17}{}}
\newlabel{pp:3}{{A.18}{78}{Proofs}{equation.1.A.0.18}{}}
\newlabel{pp:4}{{A.19}{78}{Proofs}{equation.1.A.0.19}{}}
\newlabel{pp:5}{{A.20}{78}{Proofs}{equation.1.A.0.20}{}}
\newlabel{aux:2}{{A.21}{78}{Proofs}{equation.1.A.0.21}{}}
\citation{sutton2000policy}
\newlabel{pp:6}{{A.22}{79}{Proofs}{equation.1.A.0.22}{}}
\newlabel{pp:7}{{A.23}{79}{Proofs}{equation.1.A.0.23}{}}
\newlabel{pp:8}{{A.24}{79}{Proofs}{equation.1.A.0.24}{}}
\newlabel{pp:9}{{A.25}{79}{Proofs}{equation.1.A.0.25}{}}
\newlabel{aux:3}{{A.26}{79}{Proofs}{equation.1.A.0.26}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {3.4.1}Lemma}{79}{lemma.dummy.49}}
\citation{sutton2000policy}
\newlabel{aux:4}{{A.27}{80}{Proofs}{equation.1.A.0.27}{}}
\newlabel{pp:10}{{A.28}{80}{Proofs}{equation.1.A.0.28}{}}
\newlabel{pp:11}{{A.29}{80}{Proofs}{equation.1.A.0.29}{}}
\newlabel{eq:gauss}{{A.30}{80}{Proofs}{equation.1.A.0.30}{}}
\newlabel{pp:14}{{A.31}{80}{Proofs}{equation.1.A.0.31}{}}
\newlabel{aux:5}{{A.32}{80}{Proofs}{equation.1.A.0.32}{}}
\citation{srinivas2010gaussian}
\newlabel{pp:12}{{A.33}{81}{Proofs}{equation.1.A.0.33}{}}
\newlabel{pp:13}{{A.34}{81}{Proofs}{equation.1.A.0.34}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {3.4.2}Theorem}{81}{theorem.dummy.51}}
\newlabel{aux:6}{{A.35}{81}{Proofs}{equation.1.A.0.35}{}}
\newlabel{aux:7}{{A.36}{82}{Proofs}{equation.1.A.0.36}{}}
\newlabel{aux:8}{{A.37}{82}{Proofs}{equation.1.A.0.37}{}}
\newlabel{aux:9}{{A.38}{82}{Proofs}{equation.1.A.0.38}{}}
\newlabel{pp:15}{{A.39}{82}{Proofs}{equation.1.A.0.39}{}}
\newlabel{pp:16}{{A.40}{82}{Proofs}{equation.1.A.0.40}{}}
\newlabel{aux:10}{{A.41}{82}{Proofs}{equation.1.A.0.41}{}}
\newlabel{pp:17}{{A.42}{83}{Proofs}{equation.1.A.0.42}{}}
\newlabel{pp:18}{{A.43}{83}{Proofs}{equation.1.A.0.43}{}}
\newlabel{pp:19}{{A.44}{83}{Proofs}{equation.1.A.0.44}{}}
\newlabel{pp:20}{{A.45}{83}{Proofs}{equation.1.A.0.45}{}}
\newlabel{pp:21}{{A.46}{83}{Proofs}{equation.1.A.0.46}{}}
\newlabel{pp:22}{{A.47}{83}{Proofs}{equation.1.A.0.47}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {3.4.3}Theorem}{83}{theorem.dummy.53}}
\newlabel{aux:11}{{A.48}{84}{Proofs}{equation.1.A.0.48}{}}
\newlabel{pp:23}{{A.49}{84}{Proofs}{equation.1.A.0.49}{}}
\newlabel{pp:24}{{A.50}{84}{Proofs}{equation.1.A.0.50}{}}
\newlabel{aux:12}{{A.51}{84}{Proofs}{equation.1.A.0.51}{}}
\newlabel{pp:25}{{A.52}{85}{Proofs}{equation.1.A.0.52}{}}
\newlabel{pp:26}{{A.53}{85}{Proofs}{equation.1.A.0.53}{}}
\newlabel{pp:27}{{A.54}{85}{Proofs}{equation.1.A.0.54}{}}
\newlabel{pp:28}{{A.55}{85}{Proofs}{equation.1.A.0.55}{}}
\newlabel{pp:29}{{A.56}{85}{Proofs}{equation.1.A.0.56}{}}
\newlabel{pp:30}{{A.57}{85}{Proofs}{equation.1.A.0.57}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {A.0.1}Lemma}{85}{lemma.1.A.0.1}}
\citation{hershey2007approximating}
\newlabel{eq:strangeBound}{{A.59}{86}{Proofs}{equation.1.A.0.59}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.1.1}Theorem}{86}{theorem.dummy.56}}
\citation{*}
\bibstyle{acm}
\bibdata{Bibliography/bibliography}
\bibcite{abbasi2011improved}{1}
\bibcite{agrawal1995continuum}{2}
\bibcite{agrawal1995sample}{3}
\bibcite{agrawal2013further}{4}
\bibcite{amari1998natural2}{5}
\bibcite{amari1998natural1}{6}
\bibcite{antos2008fitted}{7}
\bibcite{atan2015global}{8}
\bibcite{auer2002using}{9}
\bibcite{auer2002finite}{10}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{88}{chapter*.20}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{auer2007logarithmic}{11}
\bibcite{auer2010ucb}{12}
\bibcite{auer2007improved}{13}
\bibcite{DBLP:conf/icml/2015}{14}
\bibcite{baird1993advantage}{15}
\bibcite{baxter2001infinite}{16}
\bibcite{bellemare2016unifying}{17}
\bibcite{DBLP:conf/nips/2018}{18}
\bibcite{blei2017variational}{19}
\bibcite{blundell2015weight}{20}
\bibcite{boucheron2013concentration}{21}
\bibcite{brafman2002r}{22}
\bibcite{brockman2016openai}{23}
\bibcite{bubeck2012regret}{24}
\bibcite{bubeck2013bandits}{25}
\bibcite{bubeck2010open}{26}
\bibcite{bubeck2011x}{27}
\bibcite{bubeck2009online}{28}
\bibcite{cesa2017boltzmann}{29}
\bibcite{cesa2012combinatorial}{30}
\bibcite{chapelle2011empirical}{31}
\bibcite{chen2016combinatorial}{32}
\bibcite{chentanez2005intrinsically}{33}
\bibcite{choshen2018dora}{34}
\bibcite{sayak2018online}{35}
\bibcite{cochran2007sampling}{36}
\bibcite{cortes2010learning}{37}
\bibcite{dann2015sample}{38}
\bibcite{dann2017unifying}{39}
\bibcite{dayan1997using}{40}
\bibcite{degris2012off}{41}
\bibcite{deisenroth2013survey}{42}
\bibcite{dorato1995linear}{43}
\bibcite{DBLP:conf/icml/2018}{44}
\bibcite{espeholt2018impala}{45}
\bibcite{garivier2011kl}{46}
\bibcite{gil2013renyi}{47}
\bibcite{glynn1990likelihood}{48}
\bibcite{grondman2012survey}{49}
\bibcite{haarnoja2017reinforcement}{50}
\bibcite{haarnoja2018soft}{51}
\bibcite{hershey2007approximating}{52}
\bibcite{houthooft2016vime}{53}
\bibcite{ionides2008truncated}{54}
\bibcite{jaksch2010near}{55}
\bibcite{jin2018q}{56}
\bibcite{DBLP:conf/colt/2010}{57}
\bibcite{kallus2018instrument}{58}
\bibcite{kappen2005path}{59}
\bibcite{kaufmann2012thompson}{60}
\bibcite{kearns2002near}{61}
\bibcite{kimura1999efficient}{62}
\bibcite{kleinberg2008multi}{63}
\bibcite{kleinberg2013bandits}{64}
\bibcite{kleinberg2005nearly}{65}
\bibcite{kober2009policy}{66}
\bibcite{kong1992note}{67}
\bibcite{kupcsik2013data}{68}
\bibcite{lai1985asymptotically}{69}
\bibcite{lakshmanan2015improved}{70}
\bibcite{lange2012batch}{71}
\bibcite{lattimore2014near}{72}
\bibcite{lattimore2019bandit}{73}
\bibcite{lopes2012exploration}{74}
\bibcite{magureanu2014lipschitz}{75}
\bibcite{martino2017effective}{76}
\bibcite{masooddiversity}{77}
\bibcite{DBLP:conf/aips/2012}{78}
\bibcite{pmlr-v48-medina16}{79}
\bibcite{mersereau2009structured}{80}
\bibcite{metelli2018policy}{81}
\bibcite{mnih2016asynchronous}{82}
\bibcite{more1994line}{83}
\bibcite{jungseul2018exploration}{84}
\bibcite{oord2016pixel}{85}
\bibcite{ortner2012online}{86}
\bibcite{osband2016deep}{87}
\bibcite{osband2013more}{88}
\bibcite{osband2015bootstrapped}{89}
\bibcite{osband2017posterior}{90}
\bibcite{osband2016generalization}{91}
\bibcite{ostrovski2017count}{92}
\bibcite{oudeyer2007intrinsic}{93}
\bibcite{owen_safe_2000}{94}
\bibcite{mcbook}{95}
\bibcite{mcbook_2013}{96}
\bibcite{pandey2007multi}{97}
\bibcite{pathak2017curiosity}{98}
\bibcite{peters2008reinforcement}{99}
\bibcite{DBLP:conf/icml/2017}{100}
\bibcite{puterman2014markov}{101}
\bibcite{renyi1961measures}{102}
\bibcite{robbins1985some}{103}
\bibcite{rummery1994line}{104}
\bibcite{russo2013eluder}{105}
\bibcite{russo2018tutorial}{106}
\bibcite{sallans2004reinforcement}{107}
\bibcite{saritacc2017combinatorial}{108}
\bibcite{schmidhuber1991possibility}{109}
\bibcite{schulman2015trust}{110}
\bibcite{scott2015multivariate}{111}
\bibcite{sehnke2008policy}{112}
\bibcite{sehnke2010parameter}{113}
\bibcite{silver2014deterministic}{114}
\bibcite{srinivas2010gaussian}{115}
\bibcite{still2012information}{116}
\bibcite{strehl2009reinforcement}{117}
\bibcite{strens2000bayesian}{118}
\bibcite{sutton1988learning}{119}
\bibcite{sutton1991dyna}{120}
\bibcite{sutton2018reinforcement}{121}
\bibcite{sutton2000policy}{122}
\bibcite{tang2017exploration}{123}
\bibcite{thompson1933likelihood}{124}
\bibcite{thrun1992efficient}{125}
\bibcite{tokic2011value}{126}
\bibcite{tornio2006variational}{127}
\bibcite{vakili2011deterministic}{128}
\bibcite{veach_optimally_1995}{129}
\bibcite{wang2018regional}{130}
\bibcite{watkins1989learning}{131}
\bibcite{weinstein2012bandit}{132}
\bibcite{whitehead1991study}{133}
\bibcite{williams2006gaussian}{134}
\bibcite{williams1992simple}{135}
\bibcite{yupure}{136}
\bibcite{zhao2011analysis}{137}
\bibcite{ziebart2008maximum}{138}
