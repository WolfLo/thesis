\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{acronym}{alg}{acr}{acn}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesis.xdy}
\@glsorder{word}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{deisenroth2013survey}
\citation{gym}
\citation{scott2015multivariate}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{vi}{chapter*.3}}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{vii}{chapter*.4}}
\@writefile{toc}{\contentsline {chapter}{List of Algorithms}{viii}{chapter*.5}}
\@writefile{toc}{\contentsline {chapter}{Acronyms}{ix}{section*.6}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Challanges in RL}{1}{section.1.1}}
\citation{lai1985asymptotically}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preliminaries}{2}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Preliminaries}{{2}{2}{Preliminaries}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Multi Armed Bandits}{2}{section.2.1}}
\newlabel{sec:mab}{{2.1}{2}{Multi Armed Bandits}{section.2.1}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {definition}{\numberline {2.1.1}Definition}{3}{definition.2.1.1}}
\@writefile{loe}{\contentsline {definition}{\numberline {2.1.2}Definition}{3}{definition.2.1.2}}
\newlabel{def:immediateregret}{{2.1.2}{3}{}{definition.2.1.2}{}}
\citation{lattimore2019bandit}
\@writefile{loe}{\contentsline {definition}{\numberline {2.1.3}Definition}{4}{definition.2.1.3}}
\newlabel{def:regret}{{2.1.3}{4}{}{definition.2.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Exploration and exploitation}{4}{subsection.2.1.1}}
\newlabel{eedilemma}{{2.1.1}{4}{Exploration and exploitation}{subsection.2.1.1}{}}
\citation{lattimore2019bandit}
\citation{lattimore2019bandit}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Stochastic Bandits With Finitely Many Arms}{5}{subsection.2.1.2}}
\newlabel{finiteMABs}{{2.1.2}{5}{Stochastic Bandits With Finitely Many Arms}{subsection.2.1.2}{}}
\newlabel{eq:averagereward}{{2.3}{5}{Stochastic Bandits With Finitely Many Arms}{equation.2.1.3}{}}
\newlabel{thmt@@regretETC@data}{{\def \theequation {2.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )2.1.\@arabic {\c@equation }}\setcounter {equation}{3}}{5}{Stochastic Bandits With Finitely Many Arms}{algorithm.2.1}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {2.1.1}Theorem}{5}{theorem.2.1.1}}
\newlabel{thmt@@regretETC}{{2.1.1}{5}{}{theorem.2.1.1}{}}
\newlabel{th:regretETC}{{2.1.1}{5}{}{theorem.2.1.1}{}}
\citation{agrawal1995continuum}
\citation{magureanu2014lipschitz}
\citation{bubeck2011x}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.1}{\ignorespaces Explore-then-commit\relax }}{6}{algorithm.2.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:explorethencommit}{{2.1}{6}{Explore-then-commit\relax }{algorithm.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}$\mathcal  {X}$-armed bandits}{6}{subsection.2.1.3}}
\newlabel{sub:xarmedbandits}{{2.1.3}{6}{$\mathcal {X}$-armed bandits}{subsection.2.1.3}{}}
\citation{puterman2014markov}
\citation{sutton2018reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Markov Decision Processes}{7}{section.2.2}}
\@writefile{loe}{\contentsline {definition}{\numberline {2.2.1}Definition}{7}{definition.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Interaction protocol for Markov decision processes\relax }}{8}{figure.caption.8}}
\newlabel{fig:MDP}{{2.1}{8}{Interaction protocol for Markov decision processes\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Policies}{9}{subsection.2.2.1}}
\@writefile{loe}{\contentsline {definition}{\numberline {2.2.2}Definition}{9}{definition.2.2.2}}
\@writefile{loe}{\contentsline {remark}{\numberline {2.2.1}Remark}{9}{remark.2.2.1}}
\citation{sutton2000policy}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Performance}{10}{subsection.2.2.2}}
\newlabel{eq:Jstartstate}{{2.6}{10}{Performance}{equation.2.2.6}{}}
\newlabel{eq:ssdistribution}{{2.7}{10}{Performance}{equation.2.2.7}{}}
\citation{baird1993advantage}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Value functions}{11}{subsection.2.2.3}}
\newlabel{eq:BellmanV}{{2.11}{11}{Value functions}{equation.2.2.11}{}}
\newlabel{eq:BellmanQ}{{2.13}{11}{Value functions}{equation.2.2.13}{}}
\citation{sutton2018reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Reinforcement Learning}{12}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Problem formulation}{12}{subsection.2.3.1}}
\citation{puterman2014markov}
\citation{sutton2018reinforcement}
\newlabel{eq:optimalpolicy}{{2.15}{13}{Problem formulation}{equation.2.3.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Taxonomy}{13}{subsection.2.3.2}}
\citation{sutton1991dyna}
\citation{kupcsik2013data}
\citation{watkins1989learning}
\citation{rummery1994line}
\citation{williams1992simple}
\citation{watkins1989learning}
\citation{degris2012off}
\citation{rummery1994line}
\citation{sutton1988learning}
\citation{williams1992simple}
\citation{baxter2001infinite}
\citation{sutton2018reinforcement}
\citation{antos2008fitted}
\citation{grondman2012survey}
\citation{lange2012batch}
\citation{more1994line}
\citation{deisenroth2013survey}
\citation{sutton2000policy}
\citation{dayan1997using}
\citation{kober2009policy}
\citation{still2012information}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Policy Search}{16}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Overview}{16}{subsection.2.4.1}}
\newlabel{subsec:PSoverview}{{2.4.1}{16}{Overview}{subsection.2.4.1}{}}
\newlabel{eq:PSproblem}{{2.16}{16}{Overview}{equation.2.4.16}{}}
\citation{deisenroth2013survey}
\citation{deisenroth2013survey}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A taxonomy of \gls {PS} methods \cite  {deisenroth2013survey}\relax }}{17}{figure.caption.9}}
\newlabel{fig:PStaxonomy}{{2.2}{17}{A taxonomy of \gls {PS} methods \cite {deisenroth2013survey}\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Policy gradient}{17}{subsection.2.4.2}}
\citation{sutton2000policy}
\newlabel{eq:paramsupdate}{{2.20}{18}{Policy gradient}{equation.2.4.20}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {2.4.1}Theorem}{18}{theorem.2.4.1}}
\newlabel{th:PGtheorem}{{2.4.1}{18}{}{theorem.2.4.1}{}}
\newlabel{eq:PGtheorem}{{2.21}{18}{}{equation.2.4.21}{}}
\citation{williams1992simple}
\citation{sutton2000policy}
\citation{amari1998natural1}
\newlabel{eq:reinforcetrick}{{2.21}{19}{Policy gradient}{equation.2.4.21}{}}
\newlabel{eq:trajectoryPG}{{2.24}{19}{Policy gradient}{equation.2.4.24}{}}
\newlabel{eq:logpolicyestimate}{{2.26}{19}{Policy gradient}{equation.2.4.26}{}}
\citation{amari1998natural1}
\citation{amari1998natural2}
\citation{peters2008reinforcement}
\citation{glynn1990likelihood}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Policy gradient estimation}{20}{subsection.2.4.3}}
\citation{williams1992simple}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.2}{\ignorespaces Generic \gls {PG} algorithm\relax }}{21}{algorithm.2.2}}
\newlabel{alg:PG}{{2.2}{21}{Generic \gls {PG} algorithm\relax }{algorithm.2.2}{}}
\newlabel{step:PGestimation}{{5}{21}{Generic \gls {PG} algorithm\relax }{algorithm.2.2}{}}
\citation{williams1992simple}
\citation{peters2008reinforcement}
\citation{zhao2011analysis}
\newlabel{eq:PGbaseline}{{2.29}{22}{Policy gradient estimation}{equation.2.4.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Algorithms}{22}{subsection.2.4.4}}
\newlabel{subsec:algorithms}{{2.4.4}{22}{Algorithms}{subsection.2.4.4}{}}
\newlabel{eq:REINFORCE}{{2.30}{22}{Algorithms}{equation.2.4.30}{}}
\citation{baxter2001infinite}
\citation{sutton2000policy}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.3}{\ignorespaces Episodic REINFORCE with component-wise optimal baseline.\relax }}{23}{algorithm.2.3}}
\newlabel{alg:REINFORCE}{{2.3}{23}{Episodic REINFORCE with component-wise optimal baseline.\relax }{algorithm.2.3}{}}
\citation{peters2008reinforcement}
\citation{zhao2011analysis}
\citation{sehnke2008policy}
\citation{sehnke2010parameter}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.4}{\ignorespaces Episodic \gls {PGPE}\relax }}{25}{algorithm.2.4}}
\newlabel{alg:PGPE}{{2.4}{25}{Episodic \gls {PGPE}\relax }{algorithm.2.4}{}}
\citation{cochran2007sampling}
\citation{mcbook}
\citation{mcbook}
\citation{veach_optimally_1995}
\citation{veach_optimally_1995}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Multiple Importance Sampling}{26}{section.2.5}}
\newlabel{sec:mis}{{2.5}{26}{Multiple Importance Sampling}{section.2.5}{}}
\newlabel{eq:ise}{{2.37}{26}{Multiple Importance Sampling}{equation.2.5.37}{}}
\newlabel{eq:mise}{{2.38}{26}{Multiple Importance Sampling}{equation.2.5.38}{}}
\citation{veach_optimally_1995}
\citation{renyi1961measures}
\citation{cortes2010learning}
\citation{metelli2018policy}
\newlabel{eq:bhw}{{2.39}{27}{Multiple Importance Sampling}{equation.2.5.39}{}}
\newlabel{eq:bhe}{{2.40}{27}{Multiple Importance Sampling}{equation.2.5.40}{}}
\newlabel{eq:renyi}{{2.41}{27}{Multiple Importance Sampling}{equation.2.5.41}{}}
\newlabel{thmt@@misevarbound@data}{{\def \theequation {2.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )2.5.\@arabic {\c@equation }}\setcounter {equation}{43}}{27}{Multiple Importance Sampling}{equation.2.5.43}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {2.5.1}Lemma}{27}{lemma.2.5.1}}
\newlabel{thmt@@misevarbound}{{2.5.1}{27}{}{lemma.2.5.1}{}}
\newlabel{lem:misevarbound}{{2.5.1}{27}{}{lemma.2.5.1}{}}
\citation{thrun1992efficient}
\citation{whitehead1991study}
\citation{thrun1992efficient}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Exploration Techniques}{29}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:sota}{{3}{29}{Exploration Techniques}{chapter.3}{}}
\citation{lattimore2019bandit}
\citation{auer2002finite}
\citation{cesa2017boltzmann}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Exploration in Multi Armed Bandits}{30}{section.3.1}}
\newlabel{sec:expinmab}{{3.1}{30}{Exploration in Multi Armed Bandits}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Undirected Exploration}{30}{subsection.3.1.1}}
\citation{lai1985asymptotically}
\citation{agrawal1995continuum}
\citation{auer2002finite}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Count-based exploration and Upper Confidence Bound}{31}{subsection.3.1.2}}
\newlabel{sebsec:count&UCB}{{3.1.2}{31}{Count-based exploration and Upper Confidence Bound}{subsection.3.1.2}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {definition}{\numberline {3.1.1}Definition}{31}{definition.3.1.1}}
\newlabel{def:subgaussianity}{{3.1.1}{31}{}{definition.3.1.1}{}}
\citation{lattimore2019bandit}
\citation{auer2002finite}
\citation{agrawal1995continuum}
\@writefile{loe}{\contentsline {theorem}{\numberline {3.1.1}Theorem}{32}{theorem.3.1.1}}
\@writefile{loe}{\contentsline {corollary}{\numberline {3.1.1}Corollary}{32}{corollary.3.1.1}}
\newlabel{cor:subgaussian}{{3.1.1}{32}{}{corollary.3.1.1}{}}
\newlabel{eq:ucb}{{3.4}{32}{Count-based exploration and Upper Confidence Bound}{equation.3.1.4}{}}
\citation{auer2002finite}
\citation{auer2010ucb}
\citation{garivier2011kl}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.1}{\ignorespaces \gls {UCB}($\delta $) algorithm\relax }}{33}{algorithm.3.1}}
\newlabel{alg:ucb}{{3.1}{33}{\gls {UCB}($\delta $) algorithm\relax }{algorithm.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Optimism in the Face of Uncertainty}{33}{subsection.3.1.3}}
\citation{bubeck2011x}
\citation{kleinberg2005nearly}
\citation{kleinberg2008multi}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4} Hierarchical Optimistic Optimization}{34}{subsection.3.1.4}}
\newlabel{sub:hoo}{{3.1.4}{34}{Hierarchical Optimistic Optimization}{subsection.3.1.4}{}}
\@writefile{loe}{\contentsline {definition}{\numberline {3.1.2}Definition}{35}{definition.3.1.2}}
\newlabel{def:treeofcoverings}{{3.1.2}{35}{}{definition.3.1.2}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {3.1.1}Remark}{35}{remark.3.1.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.2}{\ignorespaces \gls {HOO} algorithm\relax }}{36}{algorithm.3.2}}
\newlabel{alg:hoo}{{3.2}{36}{\gls {HOO} algorithm\relax }{algorithm.3.2}{}}
\citation{bubeck2011x}
\citation{thompson1933likelihood}
\citation{russo2013eluder}
\@writefile{loe}{\contentsline {assumption}{\numberline {3.1.1}Assumption}{37}{assumption.3.1.1}}
\newlabel{eq:weaklipschitz}{{3.12}{37}{}{equation.3.1.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Posterior Sampling}{37}{subsection.3.1.5}}
\newlabel{sub:posteriorMAB}{{3.1.5}{37}{Posterior Sampling}{subsection.3.1.5}{}}
\citation{agrawal2013further}
\citation{bubeck2012regret}
\citation{russo2018tutorial}
\citation{srinivas2010gaussian}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Gaussian Process Upper Confidence Bound}{38}{subsection.3.1.6}}
\citation{srinivas2010gaussian}
\citation{williams2006gaussian}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.3}{\ignorespaces \gls {TS} for Bernoulli MAB with Beta priors\relax }}{39}{algorithm.3.3}}
\newlabel{alg:bernoulliTS}{{3.3}{39}{\gls {TS} for Bernoulli MAB with Beta priors\relax }{algorithm.3.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.4}{\ignorespaces \gls {GPUCB}\relax }}{40}{algorithm.3.4}}
\newlabel{alg:gpucb}{{3.4}{40}{\gls {GPUCB}\relax }{algorithm.3.4}{}}
\newlabel{eq:gpucbrule}{{3}{40}{\gls {GPUCB}\relax }{algorithm.3.4}{}}
\citation{sutton2018reinforcement}
\citation{thrun1992efficient}
\citation{cesa2017boltzmann}
\citation{sallans2004reinforcement}
\citation{kappen2005path}
\citation{ziebart2008maximum}
\citation{haarnoja2017reinforcement}
\citation{haarnoja2017reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Exploration in Reinforcement Learning}{41}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Undirected Exploration}{41}{subsection.3.2.1}}
\citation{haarnoja2017reinforcement}
\citation{haarnoja2018soft}
\citation{kearns2002near}
\citation{brafman2002r}
\citation{auer2007logarithmic}
\citation{bellemare2016unifying}
\citation{tang2017exploration}
\citation{ostrovski2017count}
\citation{choshen2018dora}
\citation{bellemare2016unifying}
\citation{ostrovski2017count}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Count-based exploration and Intrinsic Motivation}{42}{subsection.3.2.2}}
\citation{ostrovski2017count}
\citation{oord2016pixel}
\citation{lopes2012exploration}
\citation{oudeyer2007intrinsic}
\citation{chentanez2005intrinsically}
\citation{schmidhuber1991possibility}
\citation{bellemare2016unifying}
\citation{houthooft2016vime}
\citation{blei2017variational}
\citation{blundell2015weight}
\citation{houthooft2016vime}
\citation{strens2000bayesian}
\citation{osband2013more}
\citation{osband2015bootstrapped}
\citation{osband2016deep}
\citation{strens2000bayesian}
\citation{osband2017posterior}
\newlabel{eq:augmentedreward}{{3.29}{46}{Count-based exploration and Intrinsic Motivation}{equation.3.2.29}{}}
\newlabel{eq:elb}{{3.30}{46}{Count-based exploration and Intrinsic Motivation}{equation.3.2.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Posterior Sampling}{46}{subsection.3.2.3}}
\newlabel{sub:posteriorRL}{{3.2.3}{46}{Posterior Sampling}{subsection.3.2.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3.5}{\ignorespaces \gls {VIME}\relax }}{47}{algorithm.3.5}}
\newlabel{alg:VIME}{{3.5}{47}{\gls {VIME}\relax }{algorithm.3.5}{}}
\citation{metelli2018policy}
\citation{ionides2008truncated}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Optimistic Policy Search via Multiple Importance Sampling}{48}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:core}{{4}{48}{Optimistic Policy Search via Multiple Importance Sampling}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Robust Importance Sampling Estimation}{48}{section.4.1}}
\newlabel{sec:robust}{{4.1}{48}{Robust Importance Sampling Estimation}{section.4.1}{}}
\newlabel{eq:truncatedise}{{4.1}{49}{Robust Importance Sampling Estimation}{equation.4.1.1}{}}
\newlabel{eq:truncatedmise}{{4.2}{49}{Robust Importance Sampling Estimation}{equation.4.1.2}{}}
\newlabel{thmt@@truncatedbias@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.1.\@arabic {\c@equation }}\setcounter {equation}{2}}{49}{Robust Importance Sampling Estimation}{equation.4.1.2}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {lemma}{\numberline {4.1.1}Lemma}{49}{lemma.4.1.1}}
\newlabel{thmt@@truncatedbias}{{4.1.1}{49}{}{lemma.4.1.1}{}}
\newlabel{lem:truncatedbias}{{4.1.1}{49}{}{lemma.4.1.1}{}}
\newlabel{eq:biastruncated}{{4.3}{49}{}{equation.4.1.3}{}}
\newlabel{eq:variancetruncated}{{4.4}{49}{}{equation.4.1.4}{}}
\citation{bubeck2013bandits}
\citation{bubeck2013bandits}
\citation{ionides2008truncated}
\newlabel{thmt@@thrucatedconcentration@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.1.\@arabic {\c@equation }}\setcounter {equation}{4}}{50}{Robust Importance Sampling Estimation}{equation.4.1.4}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.1.1}Theorem}{50}{theorem.4.1.1}}
\newlabel{thmt@@thrucatedconcentration}{{4.1.1}{50}{}{theorem.4.1.1}{}}
\newlabel{lem:thrucatedconcentration}{{4.1.1}{50}{}{theorem.4.1.1}{}}
\newlabel{eq:1.1}{{4.5}{50}{}{equation.4.1.5}{}}
\newlabel{eq:1.2}{{4.6}{50}{}{equation.4.1.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Problem Formalization}{50}{section.4.2}}
\newlabel{sec:problem}{{4.2}{50}{Problem Formalization}{section.4.2}{}}
\newlabel{eq:theproblem}{{4.7}{50}{Problem Formalization}{equation.4.2.7}{}}
\citation{kleinberg2013bandits}
\@writefile{loe}{\contentsline {remark}{\numberline {4.2.1}Remark}{51}{remark.4.2.1}}
\citation{srinivas2010gaussian}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Algorithms}{52}{section.4.3}}
\newlabel{sec:algo}{{4.3}{52}{Algorithms}{section.4.3}{}}
\newlabel{eq:wcmu}{{4.8}{52}{Algorithms}{equation.4.3.8}{}}
\newlabel{eq:optimistindex}{{4.9}{52}{Algorithms}{equation.4.3.9}{}}
\citation{srinivas2010gaussian}
\citation{bubeck2013bandits}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.1}{\ignorespaces \gls {OPTIMIST}\relax }}{53}{algorithm.4.1}}
\newlabel{alg:1}{{4.1}{53}{\gls {OPTIMIST}\relax }{algorithm.4.1}{}}
\newlabel{line:sampling}{{2}{53}{\gls {OPTIMIST}\relax }{algorithm.4.1}{}}
\newlabel{line:optstep}{{4}{53}{\gls {OPTIMIST}\relax }{algorithm.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Regret Analysis}{53}{section.4.4}}
\newlabel{sec:regret}{{4.4}{53}{Regret Analysis}{section.4.4}{}}
\newlabel{eq:inregret}{{4.10}{53}{Regret Analysis}{equation.4.4.10}{}}
\newlabel{eq:regret}{{4.11}{53}{Regret Analysis}{equation.4.4.11}{}}
\newlabel{thmt@@boundrenyi@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{53}{Regret Analysis}{equation.4.4.11}{}}
\@writefile{loe}{\contentsline {assumption}{\numberline {4.4.1}Assumption}{54}{assumption.4.4.1}}
\newlabel{thmt@@boundrenyi}{{4.4.1}{54}{}{assumption.4.4.1}{}}
\newlabel{ass:boundrenyi}{{4.4.1}{54}{}{assumption.4.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Discrete arm set}{54}{subsection.4.4.1}}
\newlabel{thmt@@regretdiscrete@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{54}{Discrete arm set}{subsection.4.4.1}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.1}Theorem}{54}{theorem.4.4.1}}
\newlabel{thmt@@regretdiscrete}{{4.4.1}{54}{}{theorem.4.4.1}{}}
\newlabel{th:regretdiscrete}{{4.4.1}{54}{}{theorem.4.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Compact arm set}{54}{subsection.4.4.2}}
\newlabel{thmt@@lipschitz@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{54}{Compact arm set}{subsection.4.4.2}{}}
\@writefile{loe}{\contentsline {assumption}{\numberline {4.4.2}Assumption}{55}{assumption.4.4.2}}
\newlabel{thmt@@lipschitz}{{4.4.2}{55}{}{assumption.4.4.2}{}}
\newlabel{ass:lipschitz}{{4.4.2}{55}{}{assumption.4.4.2}{}}
\newlabel{thmt@@lipschitzpol@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{11}}{55}{Compact arm set}{assumption.4.4.2}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {4.4.1}Lemma}{55}{lemma.4.4.1}}
\newlabel{thmt@@lipschitzpol}{{4.4.1}{55}{}{lemma.4.4.1}{}}
\newlabel{lem:lispschitzpol}{{4.4.1}{55}{}{lemma.4.4.1}{}}
\newlabel{eq:lp1}{{4.12}{55}{}{equation.4.4.12}{}}
\newlabel{eq:lp2}{{4.13}{55}{}{equation.4.4.13}{}}
\newlabel{thmt@@regretcompact@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{13}}{55}{Compact arm set}{equation.4.4.13}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.2}Theorem}{55}{theorem.4.4.2}}
\newlabel{thmt@@regretcompact}{{4.4.2}{55}{}{theorem.4.4.2}{}}
\newlabel{th:regretcompact}{{4.4.2}{55}{}{theorem.4.4.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4.2}{\ignorespaces \gls {OPTIMIST}2\relax }}{56}{algorithm.4.2}}
\newlabel{alg:2}{{4.2}{56}{\gls {OPTIMIST}2\relax }{algorithm.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Discretization}{56}{subsection.4.4.3}}
\newlabel{thmt@@regretdiscretized@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.4.\@arabic {\c@equation }}\setcounter {equation}{13}}{56}{Discretization}{subsection.4.4.3}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.3}Theorem}{56}{theorem.4.4.3}}
\newlabel{thmt@@regretdiscretized}{{4.4.3}{56}{}{theorem.4.4.3}{}}
\newlabel{th:regretdiscretized}{{4.4.3}{56}{}{theorem.4.4.3}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {4.4.1}Remark}{56}{remark.4.4.1}}
\citation{baselines}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Numerical Simulations}{57}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:experiments}{{5}{57}{Numerical Simulations}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Practical Aspects}{57}{section.5.1}}
\newlabel{sec:practical}{{5.1}{57}{Practical Aspects}{section.5.1}{}}
\citation{gil2013renyi}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Divergence Between Gaussian Multivariate Distributions}{58}{subsection.5.1.1}}
\newlabel{thmt@@armonic@data}{{\def \theequation {5.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )5.1.\@arabic {\c@equation }}\setcounter {equation}{2}}{58}{Divergence Between Gaussian Multivariate Distributions}{subsection.5.1.1}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {theorem}{\numberline {5.1.1}Theorem}{58}{theorem.5.1.1}}
\newlabel{thmt@@armonic}{{5.1.1}{58}{}{theorem.5.1.1}{}}
\newlabel{th:armonic}{{5.1.1}{58}{}{theorem.5.1.1}{}}
\newlabel{eq:gaussianrenyi}{{5.4}{58}{Divergence Between Gaussian Multivariate Distributions}{equation.5.1.4}{}}
\citation{gil2013renyi}
\citation{gil2013renyi}
\citation{peters2008reinforcement}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Uniformly Bounded R\IeC {\'e}nyi divergence}{59}{subsection.5.1.2}}
\newlabel{subsec:boundrenyi}{{5.1.2}{59}{Uniformly Bounded Rényi divergence}{subsection.5.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Linear Quadratic Gaussian Regulator}{59}{section.5.2}}
\citation{dorato1995linear}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Environmental coefficients (left-side), task coefficients (center) and \gls {OPTIMIST} input parameters (right-side) for the \gls {LQG} experiments.\relax }}{61}{table.caption.10}}
\newlabel{tab:LQGcoeff}{{5.1}{61}{Environmental coefficients (left-side), task coefficients (center) and \gls {OPTIMIST} input parameters (right-side) for the \gls {LQG} experiments.\relax }{table.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Cumulative regret in the \gls {LQG} experiment. Comparison between \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning the hyperpolicy mean. (30 runs, 95\% c.i.)\relax }}{61}{figure.caption.11}}
\newlabel{fig:LQGcomparison}{{5.1}{61}{Cumulative regret in the \gls {LQG} experiment. Comparison between \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning the hyperpolicy mean. (30 runs, 95\% c.i.)\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Gain only}{61}{subsection.5.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces The gain parameter $\mu $ selected at each iteration of \gls {GPUCB} (left) and \gls {OPTIMIST} (right) in the \gls {LQG} experiment.\relax }}{62}{figure.caption.12}}
\newlabel{fig:LQGmu}{{5.2}{62}{The gain parameter $\mu $ selected at each iteration of \gls {GPUCB} (left) and \gls {OPTIMIST} (right) in the \gls {LQG} experiment.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Mean return of arms $\mu \in [-0.9,-0,5]$, calculated by averaging the return collected over 2000 trajectories in the \gls {LQG} experiment.\relax }}{62}{figure.caption.13}}
\newlabel{fig:LQGoptimalgain}{{5.3}{62}{Mean return of arms $\mu \in [-0.9,-0,5]$, calculated by averaging the return collected over 2000 trajectories in the \gls {LQG} experiment.\relax }{figure.caption.13}{}}
\citation{gym}
\citation{gym}
\citation{brockman2016openai}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Continuous Mountain Car experiment.\relax }}{63}{table.caption.16}}
\newlabel{tab:MCcoeff}{{5.2}{63}{Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Continuous Mountain Car experiment.\relax }{table.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Gain and standard deviation}{63}{subsection.5.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Cumulative regret in the \gls {LQG} experiment, comparing \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning both the mean and the standard deviation hyperparameters. (30 runs, 95\% c.i.)\relax }}{64}{figure.caption.14}}
\newlabel{fig:LQGcomparisonVar}{{5.4}{64}{Cumulative regret in the \gls {LQG} experiment, comparing \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning both the mean and the standard deviation hyperparameters. (30 runs, 95\% c.i.)\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Graphical representation of the Mountain Car problem \cite  {gym}.\relax }}{64}{figure.caption.15}}
\newlabel{fig:MC}{{5.5}{64}{Graphical representation of the Mountain Car problem \cite {gym}.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Continuous Mountain Car}{64}{section.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Cumulative regret in the \gls {LQG} experiment. Comparison between \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning both hyperpolicy mean and the standard deviation. (30 runs, 95\% c.i.)\relax }}{65}{figure.caption.17}}
\newlabel{fig:MCcomparison}{{5.6}{65}{Cumulative regret in the \gls {LQG} experiment. Comparison between \gls {OPTIMIST}, \gls {UCB}1 and \gls {GPUCB} when learning both hyperpolicy mean and the standard deviation. (30 runs, 95\% c.i.)\relax }{figure.caption.17}{}}
\citation{metelli2018policy}
\citation{scott2015multivariate}
\citation{scott2015multivariate}
\citation{scott2015multivariate}
\@writefile{loe}{\contentsline {remark}{\numberline {5.3.1}Remark}{66}{remark.5.3.1}}
\newlabel{rk:undiscounted}{{5.3.1}{66}{}{remark.5.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Gaussian kernel density estimation \cite  {scott2015multivariate} of the probability distribution of the arm set $\bm  {\xi }=\bm  {\mu }$ induced by \gls {PGPE} (left) and \gls {OPTIMIST} (right).\relax }}{67}{figure.caption.18}}
\newlabel{fig:MCgain}{{5.7}{67}{Gaussian kernel density estimation \cite {scott2015multivariate} of the probability distribution of the arm set $\vxi =\vmu $ induced by \gls {PGPE} (left) and \gls {OPTIMIST} (right).\relax }{figure.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Mountain Car experiment.\relax }}{67}{table.caption.19}}
\newlabel{tab:granularity}{{5.3}{67}{Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Mountain Car experiment.\relax }{table.caption.19}{}}
\@writefile{loe}{\contentsline {remark}{\numberline {5.3.2}Remark}{67}{remark.5.3.2}}
\newlabel{rk:discretization}{{5.3.2}{67}{}{remark.5.3.2}{}}
\citation{tornio2006variational}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Graphical representation of the Inverted Pendulum task.\relax }}{68}{figure.caption.20}}
\newlabel{fig:invpend}{{5.8}{68}{Graphical representation of the Inverted Pendulum task.\relax }{figure.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Inverted Pendulum experiment.\relax }}{68}{table.caption.21}}
\newlabel{tab:IPcoeff}{{5.4}{68}{Task parameters (left side) and \gls {OPTIMIST} input parameters (right side) for the Inverted Pendulum experiment.\relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Inverted Pendulum}{68}{section.5.4}}
\citation{kimura1999efficient}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Action-based setting}{70}{section.5.5}}
\newlabel{sec:actionbased}{{5.5}{70}{Action-based setting}{section.5.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces The hyperpolicy mean parameter selected at each iteration of \gls {OPTIMIST} in the Inverted Pendulum experiment.\relax }}{71}{figure.caption.22}}
\newlabel{fig:IPmu1}{{5.9}{71}{The hyperpolicy mean parameter selected at each iteration of \gls {OPTIMIST} in the Inverted Pendulum experiment.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Truncated \gls {MIS} estimator (left) and exploration bonus (right) of the arms selected by \gls {OPTIMIST} at each iteration of the Inverted Pendulum experiment.\relax }}{71}{figure.caption.23}}
\newlabel{fig:IPbound}{{5.10}{71}{Truncated \gls {MIS} estimator (left) and exploration bonus (right) of the arms selected by \gls {OPTIMIST} at each iteration of the Inverted Pendulum experiment.\relax }{figure.caption.23}{}}
\citation{martino2017effective}
\citation{kong1992note}
\citation{kong1992note}
\newlabel{eq:essrenyi}{{5.13}{72}{Action-based setting}{equation.5.5.13}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions}{73}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:conclusions}{{6}{73}{Conclusions}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Original Contributions}{73}{section.6.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Limitations and future works}{74}{section.6.2}}
\citation{metelli2018policy}
\@writefile{toc}{\contentsline {chapter}{Appendices}{76}{section*.24}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Proofs}{76}{Appendix.1.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:proof}{{A}{76}{Proofs}{Appendix.1.A}{}}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {lemma}{\numberline {2.5.1}Lemma}{76}{lemma.dummy.41}}
\newlabel{p:misevarboundline2}{{A.1}{77}{Proofs}{equation.1.A.0.1}{}}
\newlabel{p:misevarboundline5}{{A.2}{77}{Proofs}{equation.1.A.0.2}{}}
\newlabel{eq:expectationdecomposition}{{A.3}{77}{Proofs}{equation.1.A.0.3}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {4.1.1}Lemma}{77}{lemma.dummy.43}}
\newlabel{p:truncatedbias1}{{A.5}{78}{Proofs}{equation.1.A.0.5}{}}
\newlabel{p:truncatedbias2}{{A.6}{78}{Proofs}{equation.1.A.0.6}{}}
\newlabel{p:truncatedbias3}{{A.7}{78}{Proofs}{equation.1.A.0.7}{}}
\citation{boucheron2013concentration}
\newlabel{p:truncatedbias4}{{A.8}{79}{Proofs}{equation.1.A.0.8}{}}
\newlabel{p:truncatedbias5}{{A.9}{79}{Proofs}{equation.1.A.0.9}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.1.1}Theorem}{79}{theorem.dummy.45}}
\newlabel{p:thrucatedconcentration1}{{A.11}{80}{Proofs}{equation.1.A.0.11}{}}
\newlabel{p:thrucatedconcentration2}{{A.12}{80}{Proofs}{equation.1.A.0.12}{}}
\newlabel{p:thrucatedconcentration3}{{A.13}{80}{Proofs}{equation.1.A.0.13}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.1}Theorem}{80}{theorem.dummy.47}}
\newlabel{aux:1}{{A.15}{81}{Proofs}{equation.1.A.0.15}{}}
\newlabel{pp:1}{{A.16}{81}{Proofs}{equation.1.A.0.16}{}}
\newlabel{pp:2}{{A.17}{81}{Proofs}{equation.1.A.0.17}{}}
\newlabel{pp:3}{{A.18}{81}{Proofs}{equation.1.A.0.18}{}}
\newlabel{pp:4}{{A.19}{81}{Proofs}{equation.1.A.0.19}{}}
\newlabel{pp:5}{{A.20}{81}{Proofs}{equation.1.A.0.20}{}}
\newlabel{aux:2}{{A.21}{81}{Proofs}{equation.1.A.0.21}{}}
\citation{sutton2000policy}
\newlabel{pp:6}{{A.22}{82}{Proofs}{equation.1.A.0.22}{}}
\newlabel{pp:7}{{A.23}{82}{Proofs}{equation.1.A.0.23}{}}
\newlabel{pp:8}{{A.24}{82}{Proofs}{equation.1.A.0.24}{}}
\newlabel{pp:9}{{A.25}{82}{Proofs}{equation.1.A.0.25}{}}
\newlabel{aux:3}{{A.26}{82}{Proofs}{equation.1.A.0.26}{}}
\@writefile{loe}{\contentsline {lemma}{\numberline {4.4.1}Lemma}{82}{lemma.dummy.49}}
\citation{sutton2000policy}
\newlabel{aux:4}{{A.27}{83}{Proofs}{equation.1.A.0.27}{}}
\newlabel{pp:10}{{A.28}{83}{Proofs}{equation.1.A.0.28}{}}
\newlabel{pp:11}{{A.29}{83}{Proofs}{equation.1.A.0.29}{}}
\newlabel{eq:gauss}{{A.30}{83}{Proofs}{equation.1.A.0.30}{}}
\newlabel{pp:14}{{A.31}{83}{Proofs}{equation.1.A.0.31}{}}
\newlabel{aux:5}{{A.32}{83}{Proofs}{equation.1.A.0.32}{}}
\citation{srinivas2010gaussian}
\newlabel{pp:12}{{A.33}{84}{Proofs}{equation.1.A.0.33}{}}
\newlabel{pp:13}{{A.34}{84}{Proofs}{equation.1.A.0.34}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.2}Theorem}{84}{theorem.dummy.51}}
\newlabel{aux:6}{{A.35}{84}{Proofs}{equation.1.A.0.35}{}}
\newlabel{aux:7}{{A.36}{85}{Proofs}{equation.1.A.0.36}{}}
\newlabel{aux:8}{{A.37}{85}{Proofs}{equation.1.A.0.37}{}}
\newlabel{aux:9}{{A.38}{85}{Proofs}{equation.1.A.0.38}{}}
\newlabel{pp:15}{{A.39}{85}{Proofs}{equation.1.A.0.39}{}}
\newlabel{pp:16}{{A.40}{85}{Proofs}{equation.1.A.0.40}{}}
\newlabel{aux:10}{{A.41}{85}{Proofs}{equation.1.A.0.41}{}}
\newlabel{pp:17}{{A.42}{86}{Proofs}{equation.1.A.0.42}{}}
\newlabel{pp:18}{{A.43}{86}{Proofs}{equation.1.A.0.43}{}}
\newlabel{pp:19}{{A.44}{86}{Proofs}{equation.1.A.0.44}{}}
\newlabel{pp:20}{{A.46}{86}{Proofs}{equation.1.A.0.46}{}}
\newlabel{pp:21}{{A.48}{86}{Proofs}{equation.1.A.0.48}{}}
\newlabel{pp:22}{{A.52}{86}{Proofs}{equation.1.A.0.52}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {4.4.3}Theorem}{87}{theorem.dummy.53}}
\newlabel{aux:11}{{A.53}{87}{Proofs}{equation.1.A.0.53}{}}
\newlabel{pp:23}{{A.54}{87}{Proofs}{equation.1.A.0.54}{}}
\newlabel{pp:24}{{A.55}{87}{Proofs}{equation.1.A.0.55}{}}
\newlabel{aux:12}{{A.56}{87}{Proofs}{equation.1.A.0.56}{}}
\newlabel{pp:25}{{A.57}{88}{Proofs}{equation.1.A.0.57}{}}
\newlabel{pp:26}{{A.58}{88}{Proofs}{equation.1.A.0.58}{}}
\newlabel{pp:27}{{A.59}{88}{Proofs}{equation.1.A.0.59}{}}
\newlabel{pp:28}{{A.61}{88}{Proofs}{equation.1.A.0.61}{}}
\newlabel{pp:29}{{A.63}{88}{Proofs}{equation.1.A.0.63}{}}
\newlabel{pp:30}{{A.65}{88}{Proofs}{equation.1.A.0.65}{}}
\citation{hershey2007approximating}
\@writefile{loe}{\contentsline {lemma}{\numberline {A.0.1}Lemma}{89}{lemma.1.A.0.1}}
\newlabel{eq:strangeBound}{{A.69}{89}{Proofs}{equation.1.A.0.69}{}}
\@writefile{loe}{\contentsline {theorem}{\numberline {5.1.1}Theorem}{90}{theorem.dummy.56}}
\citation{*}
\bibstyle{acm}
\bibdata{Bibliography/bibliography}
\bibcite{abbasi2011improved}{1}
\bibcite{agrawal1995continuum}{2}
\bibcite{agrawal1995sample}{3}
\bibcite{agrawal2013further}{4}
\bibcite{amari1998natural2}{5}
\bibcite{amari1998natural1}{6}
\bibcite{antos2008fitted}{7}
\bibcite{atan2015global}{8}
\bibcite{auer2002using}{9}
\bibcite{auer2002finite}{10}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{92}{chapter*.25}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{auer2007logarithmic}{11}
\bibcite{auer2010ucb}{12}
\bibcite{auer2007improved}{13}
\bibcite{DBLP:conf/icml/2015}{14}
\bibcite{baird1993advantage}{15}
\bibcite{baxter2001infinite}{16}
\bibcite{bellemare2016unifying}{17}
\bibcite{DBLP:conf/nips/2018}{18}
\bibcite{blei2017variational}{19}
\bibcite{blundell2015weight}{20}
\bibcite{boucheron2013concentration}{21}
\bibcite{brafman2002r}{22}
\bibcite{gym}{23}
\bibcite{brockman2016openai}{24}
\bibcite{bubeck2012regret}{25}
\bibcite{bubeck2013bandits}{26}
\bibcite{bubeck2010open}{27}
\bibcite{bubeck2011x}{28}
\bibcite{bubeck2009online}{29}
\bibcite{cesa2017boltzmann}{30}
\bibcite{cesa2012combinatorial}{31}
\bibcite{chapelle2011empirical}{32}
\bibcite{chen2016combinatorial}{33}
\bibcite{chentanez2005intrinsically}{34}
\bibcite{choshen2018dora}{35}
\bibcite{sayak2018online}{36}
\bibcite{cochran2007sampling}{37}
\bibcite{cortes2010learning}{38}
\bibcite{dann2015sample}{39}
\bibcite{dann2017unifying}{40}
\bibcite{dayan1997using}{41}
\bibcite{degris2012off}{42}
\bibcite{deisenroth2013survey}{43}
\bibcite{baselines}{44}
\bibcite{dorato1995linear}{45}
\bibcite{DBLP:conf/icml/2018}{46}
\bibcite{espeholt2018impala}{47}
\bibcite{garivier2011kl}{48}
\bibcite{gil2013renyi}{49}
\bibcite{glynn1990likelihood}{50}
\bibcite{grondman2012survey}{51}
\bibcite{haarnoja2017reinforcement}{52}
\bibcite{haarnoja2018soft}{53}
\bibcite{hershey2007approximating}{54}
\bibcite{houthooft2016vime}{55}
\bibcite{ionides2008truncated}{56}
\bibcite{jaksch2010near}{57}
\bibcite{jin2018q}{58}
\bibcite{DBLP:conf/colt/2010}{59}
\bibcite{kallus2018instrument}{60}
\bibcite{kappen2005path}{61}
\bibcite{kaufmann2012thompson}{62}
\bibcite{kearns2002near}{63}
\bibcite{kimura1999efficient}{64}
\bibcite{kleinberg2008multi}{65}
\bibcite{kleinberg2013bandits}{66}
\bibcite{kleinberg2005nearly}{67}
\bibcite{kober2009policy}{68}
\bibcite{kong1992note}{69}
\bibcite{kupcsik2013data}{70}
\bibcite{lai1985asymptotically}{71}
\bibcite{lakshmanan2015improved}{72}
\bibcite{lange2012batch}{73}
\bibcite{lattimore2014near}{74}
\bibcite{lattimore2019bandit}{75}
\bibcite{lopes2012exploration}{76}
\bibcite{magureanu2014lipschitz}{77}
\bibcite{martino2017effective}{78}
\bibcite{masooddiversity}{79}
\bibcite{DBLP:conf/aips/2012}{80}
\bibcite{pmlr-v48-medina16}{81}
\bibcite{mersereau2009structured}{82}
\bibcite{metelli2018policy}{83}
\bibcite{mnih2016asynchronous}{84}
\bibcite{more1994line}{85}
\bibcite{jungseul2018exploration}{86}
\bibcite{oord2016pixel}{87}
\bibcite{ortner2012online}{88}
\bibcite{osband2016deep}{89}
\bibcite{osband2013more}{90}
\bibcite{osband2015bootstrapped}{91}
\bibcite{osband2017posterior}{92}
\bibcite{osband2016generalization}{93}
\bibcite{ostrovski2017count}{94}
\bibcite{oudeyer2007intrinsic}{95}
\bibcite{owen_safe_2000}{96}
\bibcite{mcbook}{97}
\bibcite{mcbook_2013}{98}
\bibcite{pandey2007multi}{99}
\bibcite{pathak2017curiosity}{100}
\bibcite{peters2008reinforcement}{101}
\bibcite{DBLP:conf/icml/2017}{102}
\bibcite{puterman2014markov}{103}
\bibcite{renyi1961measures}{104}
\bibcite{robbins1985some}{105}
\bibcite{rummery1994line}{106}
\bibcite{russo2013eluder}{107}
\bibcite{russo2018tutorial}{108}
\bibcite{sallans2004reinforcement}{109}
\bibcite{saritacc2017combinatorial}{110}
\bibcite{schmidhuber1991possibility}{111}
\bibcite{schulman2015trust}{112}
\bibcite{scott2015multivariate}{113}
\bibcite{sehnke2008policy}{114}
\bibcite{sehnke2010parameter}{115}
\bibcite{silver2014deterministic}{116}
\bibcite{srinivas2010gaussian}{117}
\bibcite{still2012information}{118}
\bibcite{strehl2009reinforcement}{119}
\bibcite{strens2000bayesian}{120}
\bibcite{sutton1988learning}{121}
\bibcite{sutton1991dyna}{122}
\bibcite{sutton2018reinforcement}{123}
\bibcite{sutton2000policy}{124}
\bibcite{tang2017exploration}{125}
\bibcite{thompson1933likelihood}{126}
\bibcite{thrun1992efficient}{127}
\bibcite{tokic2011value}{128}
\bibcite{tornio2006variational}{129}
\bibcite{vakili2011deterministic}{130}
\bibcite{veach_optimally_1995}{131}
\bibcite{wang2018regional}{132}
\bibcite{watkins1989learning}{133}
\bibcite{weinstein2012bandit}{134}
\bibcite{whitehead1991study}{135}
\bibcite{williams2006gaussian}{136}
\bibcite{williams1992simple}{137}
\bibcite{yupure}{138}
\bibcite{zhao2011analysis}{139}
\bibcite{ziebart2008maximum}{140}
\providecommand\@xdylanguage[2]{}
\@xdylanguage{acronym}{english}
\providecommand\@gls@codepage[2]{}
\@gls@codepage{acronym}{utf8}
